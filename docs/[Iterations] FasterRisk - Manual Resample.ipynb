{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccdfe217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasterrisk in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (0.1.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (2.28.2)\n",
      "Requirement already satisfied: pandas==1.5.2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn==1.2.0 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.3 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.23.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.5.2->fasterrisk) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.5.2->fasterrisk) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.2->fasterrisk) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (1.26.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %conda create -n FasterRisk python=3.9 # create a virtual environment\n",
    "# %conda activate FasterRisk # activate the virtual environment\n",
    "%pip install fasterrisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c522552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cba10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasterrisk.fasterrisk import RiskScoreOptimizer, RiskScoreClassifier\n",
    "from fasterrisk.utils import download_file_from_google_drive,  compute_logisticLoss_from_X_y_beta0_betas, get_all_product_booleans, get_support_indices, isEqual_upTo_8decimal, isEqual_upTo_16decimal, get_all_product_booleans\n",
    "\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, log_loss, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "752251b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For resampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN, ADASYN, RandomOverSampler\n",
    "# from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "# from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Ensemble Classifiers\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, cross_val_score, train_test_split, KFold, cross_validate\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, log_loss, classification_report, confusion_matrix\n",
    "\n",
    "# from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b61decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calculation_table(risk_score_model):\n",
    "    assert risk_score_model.featureNames is not None, \"please pass the featureNames to the model by using the function .reset_featureNames(featureNames)\"\n",
    "\n",
    "    nonzero_indices = get_support_indices(risk_score_model.coefficients)\n",
    "\n",
    "    max_feature_length = max([len(featureName) for featureName in risk_score_model.featureNames])\n",
    "    row_score_template = '{0}. {1:>%d}     {2:>2} point(s) | + ...' % (max_feature_length)\n",
    "\n",
    "    print(\"The Risk Score is:\")\n",
    "    for count, feature_i in enumerate(nonzero_indices):\n",
    "        row_score_str = row_score_template.format(count+1, risk_score_model.featureNames[feature_i], int(risk_score_model.coefficients[feature_i]))\n",
    "        if count == 0:\n",
    "            row_score_str = row_score_str.replace(\"+\", \" \")\n",
    "\n",
    "        print(row_score_str)\n",
    "\n",
    "    final_score_str = ' ' * (14+max_feature_length) + 'SCORE | =    '\n",
    "    print(final_score_str)\n",
    "    \n",
    "    \n",
    "    print(\"###\")\n",
    "    feature_names_list = []\n",
    "    coefficients_list = []\n",
    "    for count, feature_i in enumerate(nonzero_indices):\n",
    "        feature_names_list.append(risk_score_model.featureNames[feature_i])\n",
    "        coefficients_list.append(int(risk_score_model.coefficients[feature_i]))\n",
    "    \n",
    "    print(\"feature names: \", feature_names_list)\n",
    "    print(\"coefficients: \", coefficients_list)\n",
    "    print(len(feature_names_list) == len(coefficients_list))\n",
    "\n",
    "def print_classification_metrics(risk_score_model, X, y):\n",
    "    start = time.time()\n",
    "    y_pred = risk_score_model.predict(X)\n",
    "    stop = time.time()\n",
    "    print(f\"Predict time: {stop-start} s\")\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    # Compute the precision\n",
    "    precision = precision_score(y, y_pred)\n",
    "    print(\"Precision: {:.3f}\".format(precision))\n",
    "    # Compute the recall or sensitivity\n",
    "    recall = recall_score(y, y_pred)\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(\"F1 score: {:.3f}\".format(f1))\n",
    "    # Compute the roc auc score\n",
    "    auc = roc_auc_score(y,y_pred)\n",
    "    print(\"AUC score: {:.3f}\".format(auc))\n",
    "    # Compute the log lossscore\n",
    "    loss = log_loss(y,y_pred)\n",
    "    print(\"Log loss: {:.3f}\".format(loss))\n",
    "\n",
    "    # Assume y and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr = tp / (tp + fn) # Sensitivity\n",
    "    tnr = tn / (tn + fp) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    print(\"G-mean: {:.3f}\".format(gmean))\n",
    "\n",
    "    print(\"Specificity: {:.3f}\".format(tnr))\n",
    "\n",
    "    # Print classification report and G-mean\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "    print(\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\".format(accuracy,precision,recall,f1,auc,loss,tnr))\n",
    "\n",
    "    print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5f79555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(dataframe, sparsity=5, parent_size=10, model_index=0, random_state=0):\n",
    "    ### DATAFRAME FORMATTING ###\n",
    "    df = dataframe.copy()\n",
    "    print(df['label'].value_counts())\n",
    "    target_col = 'label'\n",
    "    df[target_col] = df[target_col].apply(lambda x: 1 if x==1 else -1) \n",
    "#     ({1: 1, 0: -1})  \n",
    "    print(df['label'].value_counts())\n",
    "    # Identify columns with boolean data type\n",
    "    bool_columns = df.select_dtypes(include=['bool']).columns\n",
    "    # Convert boolean columns to integer\n",
    "    df[bool_columns] = df[bool_columns].astype(int)\n",
    "    print(df['label'].value_counts())\n",
    "\n",
    "    ### SPLITTING THE DATA ###\n",
    "    X = df.drop(['label','account_id'], axis=1)\n",
    "    y = df['label']\n",
    "\n",
    "    # Separate minority and majority classes\n",
    "    minority_class = df[df['label'] == 1]\n",
    "    majority_class = df[df['label'] == -1]\n",
    "    print(len(majority_class), len(minority_class))\n",
    "    # Undersample majority class\n",
    "    start_sampling_time = time.time()\n",
    "    undersampled_majority_class = resample(majority_class, \n",
    "                                          replace=False, \n",
    "                                          n_samples=len(minority_class),\n",
    "                                           random_state=random_state\n",
    "                                          )\n",
    "    stop_sampling_time = time.time()\n",
    "    sampling_time = stop_sampling_time - start_sampling_time\n",
    "    # Combine minority class with undersampled majority class\n",
    "    undersampled_data = pd.concat([minority_class, undersampled_majority_class])\n",
    "\n",
    "    # Split the undersampled data into training, validation, and test sets\n",
    "    X_undersampled = undersampled_data.drop(['label','account_id'], axis=1)\n",
    "    y_undersampled = undersampled_data['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_undersampled, y_undersampled, test_size=0.2,random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25,random_state=random_state)\n",
    "\n",
    "    # Print the number of examples in each set\n",
    "    print(\"Number of examples in the training set: \", len(X_train))\n",
    "    print(\"Number of examples in the validation set: \", len(X_val))\n",
    "    print(\"Number of examples in the test set: \", len(X_test))\n",
    "    # Calculate the desired number of samples for each class based on the proportion in the test dataset\n",
    "    desired_majority_samples = int(len(X_test) * 0.90)\n",
    "    desired_minority_samples = int(len(X_test) * 0.10)\n",
    "\n",
    "    print(\"desired\",desired_majority_samples, desired_minority_samples)\n",
    "    # Resample the majority class in the test dataset\n",
    "    resampled_majority_class = resample(majority_class,\n",
    "                                        replace=True,\n",
    "                                        n_samples=desired_majority_samples,\n",
    "                                        random_state=random_state\n",
    "                                        )\n",
    "\n",
    "    # Sample the minority class in the test dataset\n",
    "    sampled_minority_class = resample(minority_class,\n",
    "                                      replace=True,\n",
    "                                      n_samples=desired_minority_samples,\n",
    "                                      random_state=random_state\n",
    "                                      )\n",
    "\n",
    "    test_imbalanced = pd.concat([resampled_majority_class, sampled_minority_class])\n",
    "    X_test_imbalanced = test_imbalanced.drop(['label', 'account_id'], axis=1)\n",
    "    y_test_imbalanced= test_imbalanced['label']\n",
    "\n",
    "#     print(\"Number of examples in the test imbalanced set: \", len(X_test_imbalanced))\n",
    "#     # Print the number of examples in each class in the imbalanced test dataset\n",
    "#     print(\"Number of examples in the imbalanced test dataset (label -1):\", len(y_test_imbalanced[y_test_imbalanced == -1]))\n",
    "#     print(\"Number of examples in the imbalanced test dataset (label 1):\", len(y_test_imbalanced[y_test_imbalanced == 1]))\n",
    "      \n",
    "    ### CONVERT TO NUMPY ###\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_val = np.asarray(X_val)\n",
    "    y_val = np.asarray(y_val)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    X_test_imbalanced = np.asarray(X_test_imbalanced)\n",
    "    y_test_imbalanced = np.asarray(y_test_imbalanced)\n",
    "\n",
    "    ### MODELLING ###\n",
    "    RiskScoreOptimizer_m = RiskScoreOptimizer(X = X_train, y = y_train, k = sparsity, parent_size = parent_size)\n",
    "    start_training_time = time.time()\n",
    "    RiskScoreOptimizer_m.optimize()\n",
    "    stop_training_time = time.time()\n",
    "    training_time = stop_training_time - start_training_time\n",
    "\n",
    "    multipliers, sparseDiversePool_beta0_integer, sparseDiversePool_betas_integer = RiskScoreOptimizer_m.get_models()\n",
    "    print(\"We generate {} risk score models from the sparse diverse pool\".format(len(multipliers)))\n",
    "    \n",
    "#     model_index = 0 # first model\n",
    "    multiplier = multipliers[model_index]\n",
    "    intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "    coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "    model = RiskScoreClassifier(multiplier, intercept, coefficients)\n",
    "    X_featureNames = list(X.columns)\n",
    "\n",
    "    model.reset_featureNames(X_featureNames)\n",
    "    model.print_model_card()\n",
    "    ### RESULTS ###\n",
    "    ## Val\n",
    "    start_pred_val = time.time()\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    stop_pred_val = time.time()\n",
    "    pred_val_time = stop_pred_val - start_pred_val\n",
    "\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    precision_val = precision_score(y_val, y_pred_val)\n",
    "    recall_val = recall_score(y_val, y_pred_val)\n",
    "    f1_val = f1_score(y_val, y_pred_val)\n",
    "    auc_val = roc_auc_score(y_val,y_pred_val)\n",
    "    loss_val = log_loss(y_val,y_pred_val)\n",
    "    # Assume y_val and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_val = tp_val / (tp_val + fn_val) # Sensitivity\n",
    "    tnr_val = tn_val / (tn_val + fp_val) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_val = np.sqrt(tpr_val * tnr_val) \n",
    "    ## Test\n",
    "    start_pred_test = time.time()\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    stop_pred_test = time.time()\n",
    "    pred_test_time = stop_pred_test - start_pred_test\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    auc_test = roc_auc_score(y_test,y_pred_test)\n",
    "    loss_test = log_loss(y_test,y_pred_test)\n",
    "    # Assume y_test and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test = tp_test / (tp_test + fn_test) # Sensitivity\n",
    "    tnr_test = tn_test / (tn_test + fp_test) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test = np.sqrt(tpr_test * tnr_test)\n",
    "    \n",
    "    ## test imbalanced\n",
    "    start_pred_test_imbalanced = time.time()\n",
    "    y_pred_test_imbalanced = model.predict(X_test_imbalanced)\n",
    "    stop_pred_test_imbalanced = time.time()\n",
    "    pred_test_imbalanced_time = stop_pred_test_imbalanced - start_pred_test_imbalanced\n",
    "\n",
    "    accuracy_test_imbalanced = accuracy_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    precision_test_imbalanced = precision_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    recall_test_imbalanced = recall_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    f1_test_imbalanced = f1_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    auc_test_imbalanced = roc_auc_score(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    loss_test_imbalanced = log_loss(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    # Assume y_test_imbalanced and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test_imbalanced, fp_test_imbalanced, fn_test_imbalanced, tp_test_imbalanced = confusion_matrix(y_test_imbalanced, y_pred_test_imbalanced).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test_imbalanced = tp_test_imbalanced / (tp_test_imbalanced + fn_test_imbalanced) # Sensitivity\n",
    "    tnr_test_imbalanced = tn_test_imbalanced / (tn_test_imbalanced + fp_test_imbalanced) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test_imbalanced = np.sqrt(tpr_test_imbalanced * tnr_test_imbalanced) \n",
    "\n",
    "    print(confusion_matrix(y_test_imbalanced,y_pred_test_imbalanced))\n",
    "    val_results = [accuracy_val, precision_val, recall_val, f1_val, auc_val, loss_val, tnr_val]\n",
    "    test_results = [accuracy_test, precision_test, recall_test, f1_test, auc_test, loss_test, tnr_test]\n",
    "    test_imbalanced_results = [accuracy_test_imbalanced, precision_test_imbalanced, recall_test_imbalanced, f1_test_imbalanced, auc_test_imbalanced, loss_test_imbalanced, tnr_test_imbalanced]\n",
    "\n",
    "    time_results = [training_time, pred_val_time, pred_test_time, pred_test_imbalanced_time, sampling_time]\n",
    "    return val_results, test_results, test_imbalanced_results, time_results\n",
    "    # return accuracy, precision, recall, f1, auc, loss, tnr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45839155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iterations(df,sparsity,parent_size,model_index, iterations=5):\n",
    "    results = []\n",
    "    random_state = [12,23,34,45,56]\n",
    "    for i in range(len(random_state)):\n",
    "        val_results, test_results, test_imbalanced_results, time_results = train_and_evaluate_model(df,sparsity,parent_size,model_index,random_state[i])\n",
    "        concatted_results = val_results + test_results + test_imbalanced_results + time_results\n",
    "    \n",
    "        results.append(concatted_results)\n",
    "\n",
    "    columns = ['Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1', 'Val AUC', 'Val Loss', 'Val Specificity',\n",
    "               'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test AUC', 'Test Loss', 'Test Specificity',\n",
    "               'Test Imbalanced Accuracy', 'Test Imbalanced Precision', 'Test Imbalanced Recall', 'Test Imbalanced F1', 'Test Imbalanced AUC', 'Test Imbalanced Loss', 'Test Imbalanced Specificity',\n",
    "               'Training Time', 'Pred Val Time', 'Pred Test Time', 'Pred Test Imbalanced Time', 'Sampling Time'\n",
    "               ]\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    print(df)\n",
    "    stats = df.describe().loc[['mean']]\n",
    "    # stats = df.describe()\n",
    "    print(stats)\n",
    "    return stats.to_csv(sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37490b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name ='data_f'\n",
    "dataset_file_path = '../dataset/' + dataset_name + '.csv'\n",
    "# train_data_file_path = \"../dataset/\"+ dataset_name + \"_train.csv\"\n",
    "# test_data_file_path = \"../dataset/\"+ dataset_name + \"_test.csv\"\n",
    "# val_data_file_path = \"../dataset/\"+ dataset_name + \"_val.csv\"\n",
    "# test_imbalanced_data_file_path = \"../dataset/\"+ dataset_name + \"_test_imbalanced.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3739e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'label'\n",
    "\n",
    "df = pd.read_csv(dataset_file_path)\n",
    "df[target_col] = df[target_col].map({1: 1, 0: -1})  \n",
    "# Identify columns with boolean data type\n",
    "bool_columns = df.select_dtypes(include=['bool']).columns\n",
    "# Convert boolean columns to integer\n",
    "df[bool_columns] = df[bool_columns].astype(int)\n",
    "\n",
    "\n",
    "# data = np.asarray(df)\n",
    "# X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a97c6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate_model(df,5,10,0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "463e1cf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ad5d3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "desired 1126 125\n",
      "(3753, 11)\n",
      "We generate 11 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      4 point(s) |   ...\n",
      "2.                      promo_amount      4 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      4 point(s) | + ...\n",
      "4.           category_f_promo_amount      4 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   4.0  |   6.0  |   8.0  |\n",
      "RISK  |  50.0% |  93.2% |  99.5% | 100.0% | 100.0% |\n",
      "SCORE |  10.0  |  12.0  |  14.0  |  16.0  |  18.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "[[1030   96]\n",
      " [  87   38]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "desired 1126 125\n",
      "(3753, 11)\n",
      "We generate 11 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      price_amount      3 point(s) | + ...\n",
      "3.                      promo_amount      2 point(s) | + ...\n",
      "4. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "5.           category_f_promo_amount      3 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   3.0  |   5.0  |   6.0  |\n",
      "RISK  |  50.0% |  97.8% |  99.7% | 100.0% | 100.0% |\n",
      "SCORE |   8.0  |   9.0  |  11.0  |  12.0  |  14.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "[[   2 1124]\n",
      " [   0  125]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "desired 1126 125\n",
      "(3753, 11)\n",
      "We generate 11 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      5 point(s) |   ...\n",
      "2.                      promo_amount      5 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      5 point(s) | + ...\n",
      "4.           category_f_promo_amount      5 point(s) | + ...\n",
      "5.               similar_email_count      3 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   3.0  |   5.0  |   8.0  |  10.0  |\n",
      "RISK  |  50.0% |  95.6% |  99.4% | 100.0% | 100.0% |\n",
      "SCORE |  13.0  |  15.0  |  18.0  |  20.0  |  23.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "[[1033   93]\n",
      " [  75   50]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "desired 1126 125\n",
      "(3753, 11)\n",
      "We generate 11 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      promo_amount      2 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "4.           category_f_promo_amount      3 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |  50.0% |  97.8% |  99.7% |  99.9% | 100.0% | 100.0% |\n",
      "SCORE |   7.0  |   8.0  |   9.0  |  10.0  |  11.0  |  13.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "[[1041   85]\n",
      " [  69   56]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "desired 1126 125\n",
      "(3753, 11)\n",
      "We generate 11 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      promo_amount      2 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "4.           category_f_promo_amount      3 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |  50.0% |  97.8% |  99.7% |  99.9% | 100.0% | 100.0% |\n",
      "SCORE |   7.0  |   8.0  |   9.0  |  10.0  |  11.0  |  13.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "[[1032   94]\n",
      " [  68   57]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.651479       0.858696    0.373817  0.520879  0.655304  12.561977   \n",
      "1      0.487610       0.487159    0.996716  0.654447  0.500694  18.468411   \n",
      "2      0.677858       0.816667    0.413153  0.548712  0.664783  11.611185   \n",
      "3      0.642686       0.816393    0.389062  0.526984  0.648705  12.878907   \n",
      "4      0.666667       0.821086    0.415858  0.552095  0.663695  12.014551   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.936791       0.670927        0.817869     0.398660  ...   \n",
      "1         0.004673       0.518371        0.518371     1.000000  ...   \n",
      "2         0.916413       0.666134        0.810631     0.403306  ...   \n",
      "3         0.908347       0.656550        0.837545     0.376013  ...   \n",
      "4         0.911532       0.670927        0.850174     0.398042  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.304            0.293436             0.609371   \n",
      "1                   1.000            0.181951             0.500888   \n",
      "2                   0.400            0.373134             0.658703   \n",
      "3                   0.448            0.421053             0.686256   \n",
      "4                   0.456            0.413043             0.686259   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0              5.272573                     0.914742       0.300413   \n",
      "1             32.384545                     0.001776       0.329193   \n",
      "2              4.840395                     0.917407       0.251404   \n",
      "3              4.437028                     0.924512       0.430907   \n",
      "4              4.667523                     0.916519       0.325969   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling Time  \n",
      "0       0.000103        0.000019                   0.000017       0.001946  \n",
      "1       0.000042        0.000018                   0.000018       0.001588  \n",
      "2       0.000158        0.000020                   0.000019       0.001575  \n",
      "3       0.000026        0.000019                   0.000020       0.001656  \n",
      "4       0.000022        0.000019                   0.000019       0.001585  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "mean       0.62526           0.76    0.517721  0.560623  0.626636  13.507006   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.735551       0.636581        0.766918     0.515204  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                  0.5216            0.336523             0.628296   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean             10.320413                     0.734991       0.327577   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling Time  \n",
      "mean        0.00007        0.000019                   0.000018        0.00167  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling Time\n",
      "mean\t0.6252597921662669\t0.7600001863903169\t0.5177213049254067\t0.5606234830565429\t0.626636307715123\t13.507006162124796\t0.7355513105048396\t0.6365814696485623\t0.766918118890772\t0.5152042263886202\t0.5637407583765773\t0.6268847396835572\t13.098931543169574\t0.738565252978494\t0.7136690647482015\t0.3015918135059629\t0.5216000000000001\t0.33652344821914915\t0.6282955595026641\t10.320412984797574\t0.7349911190053285\t0.3275771617889404\t7.01904296875e-05\t1.8978118896484374e-05\t1.845359802246094e-05\t0.0016699790954589843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_iterations(df,5,10,0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71798ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f49f895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705a4691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
