{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "qz8knwF-VxFi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import time\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For resampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN, ADASYN, RandomOverSampler\n",
    "# from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "# from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Ensemble Classifiers\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, KFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, log_loss, classification_report, confusion_matrix\n",
    "\n",
    "# from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "p33D0MljmXB1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth, drive\n",
    "# from google.auth import default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMBZd1lCmbN_",
    "outputId": "f4406a20-b3e0-4d44-d1cf-9f9686bc7b67"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5rNCI-nH6o9"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "rMLy4xPTWgUs"
   },
   "outputs": [],
   "source": [
    "# drive_path = '/content/drive/MyDrive/TA/Dataset/'\n",
    "drive_path = '../dataset/'\n",
    "dataset_name = 'data_f'\n",
    "df = pd.read_csv(drive_path + dataset_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "Iw8zHrcCXi_a",
    "outputId": "cb147ad5-adb4-47be-fa67-0d81883559d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>order_count_with_promo</th>\n",
       "      <th>price_amount</th>\n",
       "      <th>promo_amount</th>\n",
       "      <th>category_f_order_count_with_promo</th>\n",
       "      <th>category_f_promo_amount</th>\n",
       "      <th>similar_device_count</th>\n",
       "      <th>similar_email_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34634632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27536039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29164748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28115239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33491857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  order_count_with_promo  price_amount  promo_amount  \\\n",
       "0    34634632                     0.0      0.000108           0.0   \n",
       "1    27536039                     0.0      0.000032           0.0   \n",
       "2    29164748                     0.0      0.000015           0.0   \n",
       "3    28115239                     0.0      0.000016           0.0   \n",
       "4    33491857                     0.0      0.000050           0.0   \n",
       "\n",
       "   category_f_order_count_with_promo  category_f_promo_amount  \\\n",
       "0                                0.0                      0.0   \n",
       "1                                0.0                      0.0   \n",
       "2                                0.0                      0.0   \n",
       "3                                0.0                      0.0   \n",
       "4                                0.0                      0.0   \n",
       "\n",
       "   similar_device_count  similar_email_count  label  \n",
       "0                   0.0                  0.0      1  \n",
       "1                   0.0                  0.0      0  \n",
       "2                   0.0                  0.0      0  \n",
       "3                   0.0                  0.0      0  \n",
       "4                   0.0                  0.0      0  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vw6cy2RqXlTx",
    "outputId": "d7b168c8-ed6b-473d-e0e8-68d16c05c75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71544 entries, 0 to 71543\n",
      "Data columns (total 9 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   account_id                         71544 non-null  int64  \n",
      " 1   order_count_with_promo             71544 non-null  float64\n",
      " 2   price_amount                       71544 non-null  float64\n",
      " 3   promo_amount                       71544 non-null  float64\n",
      " 4   category_f_order_count_with_promo  71544 non-null  float64\n",
      " 5   category_f_promo_amount            71544 non-null  float64\n",
      " 6   similar_device_count               71544 non-null  float64\n",
      " 7   similar_email_count                71544 non-null  float64\n",
      " 8   label                              71544 non-null  int64  \n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 4.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OsjS9iuxOxH",
    "outputId": "8f33ec9a-f626-4509-dd54-e16375baebe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68416\n",
       "1     3128\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kN1FbuDowM8A",
    "outputId": "944eff1e-6c29-42f7-a486-e786871d7d02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.956279\n",
       "1    0.043721\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGtWYlunCReA"
   },
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "vP4Nwy5eIBaA"
   },
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop(['label','account_id'], axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T05DKwpOw7GY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "776gNRr3Kyit"
   },
   "outputs": [],
   "source": [
    "# print(len(X_train.columns))\n",
    "# print(len(X_val.columns))\n",
    "# print(len(X_test.columns))\n",
    "# print(len(X_test_imbalanced.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "TMY3TEjjLJdW"
   },
   "outputs": [],
   "source": [
    "# print(len(y_train))\n",
    "# print(len(y_val))\n",
    "# print(len(y_test))\n",
    "# print(len(y_test_imbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "y1NDznUibb2I"
   },
   "outputs": [],
   "source": [
    "# y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "b3OfbSfIbgB_"
   },
   "outputs": [],
   "source": [
    "# y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "id": "ZrkESd8DbiXm"
   },
   "outputs": [],
   "source": [
    "# y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "fmoeKPjjIMi5"
   },
   "outputs": [],
   "source": [
    "# y_test_imbalanced.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b5t7El9po9b"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "FqOR2TkY0U3I"
   },
   "outputs": [],
   "source": [
    "def print_classification_metrics(y_true, y_pred):\n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    # Compute the precision\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    print(\"Precision: {:.3f}\".format(precision))\n",
    "    # Compute the recall or sensitivity\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(\"F1 score: {:.3f}\".format(f1))\n",
    "    # Compute the roc auc score\n",
    "    auc = roc_auc_score(y_true,y_pred)\n",
    "    print(\"AUC score: {:.3f}\".format(auc))\n",
    "    # Compute the log lossscore\n",
    "    loss = log_loss(y_true,y_pred)\n",
    "    print(\"Log loss: {:.3f}\".format(loss))\n",
    "\n",
    "    # Assume y_true and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr = tp / (tp + fn) # Sensitivity\n",
    "    tnr = tn / (tn + fp) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    print(\"G-mean: {:.3f}\".format(gmean))\n",
    "\n",
    "    print(\"Specificity: {:.3f}\".format(tnr))\n",
    "\n",
    "    # Print classification report and G-mean\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\".format(accuracy,precision,recall,f1,auc,loss,tnr))\n",
    "\n",
    "    print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "0PSidu9KOKAH"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X, y, random_state):\n",
    "    ### SPLITTING THE DATA ###\n",
    "    # Separate minority and majority classes\n",
    "    minority_class = df[df['label'] == 1]\n",
    "    majority_class = df[df['label'] == 0]\n",
    "\n",
    "    # Undersample majority class\n",
    "    start_sampling_time = time.time()\n",
    "    undersampled_majority_class = resample(majority_class, \n",
    "                                          replace=False, \n",
    "                                          n_samples=len(minority_class),\n",
    "                                           random_state=random_state\n",
    "                                          )\n",
    "    stop_sampling_time = time.time()\n",
    "    sampling_time = stop_sampling_time - start_sampling_time\n",
    "    # Combine minority class with undersampled majority class\n",
    "    undersampled_data = pd.concat([minority_class, undersampled_majority_class])\n",
    "\n",
    "    # Split the undersampled data into training, validation, and test sets\n",
    "    X_undersampled = undersampled_data.drop(['label','account_id'], axis=1)\n",
    "    y_undersampled = undersampled_data['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_undersampled, y_undersampled, test_size=0.2, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25,random_state=random_state)\n",
    "\n",
    "    # Print the number of examples in each set\n",
    "    print(\"Number of examples in the training set: \", len(X_train))\n",
    "    print(\"Number of examples in the validation set: \", len(X_val))\n",
    "    print(\"Number of examples in the test set: \", len(X_test))\n",
    "  \n",
    "    # Calculate the desired number of samples for each class based on the proportion in the test dataset\n",
    "    desired_majority_samples = int(len(X_test) * 0.90)\n",
    "    desired_minority_samples = int(len(X_test) * 0.10)\n",
    "\n",
    "    # Resample the majority class in the test dataset\n",
    "    resampled_majority_class = resample(majority_class,\n",
    "                                        replace=True,\n",
    "                                        n_samples=desired_majority_samples,\n",
    "                                        random_state=random_state\n",
    "                                        )\n",
    "\n",
    "    # Sample the minority class in the test dataset\n",
    "    sampled_minority_class = resample(minority_class,\n",
    "                                      replace=True,\n",
    "                                      n_samples=desired_minority_samples,\n",
    "                                      random_state=random_state\n",
    "                                      )\n",
    "\n",
    "    test_imbalanced = pd.concat([resampled_majority_class, sampled_minority_class])\n",
    "    X_test_imbalanced = test_imbalanced.drop(['label', 'account_id'], axis=1)\n",
    "    y_test_imbalanced= test_imbalanced['label']\n",
    "\n",
    "    # Print the number of examples in each class in the imbalanced test dataset\n",
    "    print(\"Number of examples in the imbalanced test dataset (label 0):\", len(y_test_imbalanced[y_test_imbalanced == 0]))\n",
    "    print(\"Number of examples in the imbalanced test dataset (label 1):\", len(y_test_imbalanced[y_test_imbalanced == 1]))\n",
    "      \n",
    "    ### MODELLING ###\n",
    "    start_training_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    stop_training_time = time.time()\n",
    "    training_time = stop_training_time - start_training_time\n",
    "\n",
    "    ### RESULTS ###\n",
    "    ## Val\n",
    "    start_pred_val = time.time()\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    stop_pred_val = time.time()\n",
    "    pred_val_time = stop_pred_val - start_pred_val\n",
    "\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    precision_val = precision_score(y_val, y_pred_val)\n",
    "    recall_val = recall_score(y_val, y_pred_val)\n",
    "    f1_val = f1_score(y_val, y_pred_val)\n",
    "    auc_val = roc_auc_score(y_val,y_pred_val)\n",
    "    loss_val = log_loss(y_val,y_pred_val)\n",
    "    # Assume y_val and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_val = tp_val / (tp_val + fn_val) # Sensitivity\n",
    "    tnr_val = tn_val / (tn_val + fp_val) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_val = np.sqrt(tpr_val * tnr_val) \n",
    "    ## Test\n",
    "    start_pred_test = time.time()\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    stop_pred_test = time.time()\n",
    "    pred_test_time = stop_pred_test - start_pred_test\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    auc_test = roc_auc_score(y_test,y_pred_test)\n",
    "    loss_test = log_loss(y_test,y_pred_test)\n",
    "    # Assume y_test and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test = tp_test / (tp_test + fn_test) # Sensitivity\n",
    "    tnr_test = tn_test / (tn_test + fp_test) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test = np.sqrt(tpr_test * tnr_test)\n",
    "    \n",
    "    ## test imbalanced\n",
    "    start_pred_test_imbalanced = time.time()\n",
    "    y_pred_test_imbalanced = model.predict(X_test_imbalanced)\n",
    "    stop_pred_test_imbalanced = time.time()\n",
    "    pred_test_imbalanced_time = stop_pred_test_imbalanced - start_pred_test_imbalanced\n",
    "\n",
    "    accuracy_test_imbalanced = accuracy_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    precision_test_imbalanced = precision_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    recall_test_imbalanced = recall_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    f1_test_imbalanced = f1_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    auc_test_imbalanced = roc_auc_score(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    loss_test_imbalanced = log_loss(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    # Assume y_test_imbalanced and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test_imbalanced, fp_test_imbalanced, fn_test_imbalanced, tp_test_imbalanced = confusion_matrix(y_test_imbalanced, y_pred_test_imbalanced).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test_imbalanced = tp_test_imbalanced / (tp_test_imbalanced + fn_test_imbalanced) # Sensitivity\n",
    "    tnr_test_imbalanced = tn_test_imbalanced / (tn_test_imbalanced + fp_test_imbalanced) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test_imbalanced = np.sqrt(tpr_test_imbalanced * tnr_test_imbalanced) \n",
    "\n",
    "    print(confusion_matrix(y_test_imbalanced, y_pred_test_imbalanced))\n",
    "    val_results = [accuracy_val, precision_val, recall_val, f1_val, auc_val, loss_val, tnr_val]\n",
    "    test_results = [accuracy_test, precision_test, recall_test, f1_test, auc_test, loss_test, tnr_test]\n",
    "    test_imbalanced_results = [accuracy_test_imbalanced, precision_test_imbalanced, recall_test_imbalanced, f1_test_imbalanced, auc_test_imbalanced, loss_test_imbalanced, tnr_test_imbalanced]\n",
    "\n",
    "    time_results = [training_time, pred_val_time, pred_test_time, pred_test_imbalanced_time, sampling_time]\n",
    "    return val_results, test_results, test_imbalanced_results, time_results\n",
    "    # return accuracy, precision, recall, f1, auc, loss, tnr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "kXQqS7aaQvg1"
   },
   "outputs": [],
   "source": [
    "def run_iterations(model, X, y, iterations=5):\n",
    "    results = []\n",
    "    random_state = [12,23,34,45,56]\n",
    "    for i in range(len(random_state)):\n",
    "        val_results, test_results, test_imbalanced_results, time_results = train_and_evaluate_model(model, X, y, random_state[i])\n",
    "        concatted_results = val_results + test_results + test_imbalanced_results + time_results\n",
    "    \n",
    "        results.append(concatted_results)\n",
    "\n",
    "    columns = ['Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1', 'Val AUC', 'Val Loss', 'Val Specificity',\n",
    "               'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test AUC', 'Test Loss', 'Test Specificity',\n",
    "               'Test Imbalanced Accuracy', 'Test Imbalanced Precision', 'Test Imbalanced Recall', 'Test Imbalanced F1', 'Test Imbalanced AUC', 'Test Imbalanced Loss', 'Test Imbalanced Specificity',\n",
    "               'Training Time', 'Pred Val Time', 'Pred Test Time', 'Pred Test Imbalanced Time','Sampling_Time'\n",
    "               ]\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    print(df)\n",
    "    stats = df.describe().loc[['mean']]\n",
    "    # stats = df.describe()\n",
    "    print(stats)\n",
    "    return stats.to_csv(sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "4E5IscywJnxD"
   },
   "outputs": [],
   "source": [
    "# def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "#     recall = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     auc = roc_auc_score(y_test,y_pred)\n",
    "#     loss = log_loss(y_test,y_pred)\n",
    "#     # Assume y_test and y_pred are the true and predicted labels for a binary classification problem\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#     # Calculate TPR and TNR\n",
    "#     tpr = tp / (tp + fn) # Sensitivity\n",
    "#     tnr = tn / (tn + fp) # Specificity\n",
    "#     # Calculate G-mean\n",
    "#     gmean = np.sqrt(tpr * tnr)\n",
    "#     return accuracy, precision, recall, f1, auc, loss, tnr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "ud_rXwDLLSzq"
   },
   "outputs": [],
   "source": [
    "# def run_iterations(model, X_train, y_train, X_test, y_test, iterations=5):\n",
    "#     results = []\n",
    "#     for i in range(iterations):\n",
    "#         accuracy, precision, recall, f1, auc, loss, tnr = train_and_evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "#         results.append([accuracy, precision, recall, f1, auc, loss, tnr])\n",
    "#     columns = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC', 'Loss', 'Specificity']\n",
    "#     df = pd.DataFrame(results, columns=columns)\n",
    "#     print(df)\n",
    "#     median = df.median()\n",
    "#     return median.to_csv(sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "zlsQKnxQIs3_"
   },
   "outputs": [],
   "source": [
    "def plot_auc(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.lineplot(fpr, tpr, label='AUC = %0.2f' % roc_auc)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "Lsu_EEI7klPU"
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(rfc, feature_names):\n",
    "    importances = rfc.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    names = [feature_names[i] for i in indices]\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.bar(range(len(feature_names)), importances[indices])\n",
    "    plt.xticks(range(len(feature_names)), names, rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "reLU6OXp_BqB"
   },
   "outputs": [],
   "source": [
    "# df_2_train = pd.concat([X_train, y_train], axis=1)\n",
    "# df_2_test = pd.concat([X_test, y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "6zlOBWie_BqC"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# df_2_test.to_csv('df_2_test.csv', index=False)\n",
    "\n",
    "# # Download the CSV file to your local machine\n",
    "# files.download('df_2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZgEY9lPKzML",
    "outputId": "401bb74b-7eb9-4c7b-f68f-5275a1949ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71544 entries, 0 to 71543\n",
      "Data columns (total 9 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   account_id                         71544 non-null  int64  \n",
      " 1   order_count_with_promo             71544 non-null  float64\n",
      " 2   price_amount                       71544 non-null  float64\n",
      " 3   promo_amount                       71544 non-null  float64\n",
      " 4   category_f_order_count_with_promo  71544 non-null  float64\n",
      " 5   category_f_promo_amount            71544 non-null  float64\n",
      " 6   similar_device_count               71544 non-null  float64\n",
      " 7   similar_email_count                71544 non-null  float64\n",
      " 8   label                              71544 non-null  int64  \n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 4.9 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlI99wRS6O8x",
    "outputId": "c2cf7d3e-ba14-42b4-fa55-8987bd52c082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df.isna().sum()\n",
    "selected_data = df.columns.isin(counts[(counts > 0 )].index)\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6rMLdhb6WnF",
    "outputId": "ea9307fb-9ec1-4004-b161-41269a19b300"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71544"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "rtujcoSWXI3l"
   },
   "outputs": [],
   "source": [
    "# X[X['day_to_first_transaction'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXpix0qfkdut"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3DOF7HI-4lC"
   },
   "source": [
    "## Base Model (Random Forest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r3s1YRlP-4lD",
    "outputId": "4962aea2-4e2f-47af-dc4d-0e311f8fbbaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[683 443]\n",
      " [ 28  97]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[707 419]\n",
      " [ 28  97]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[686 440]\n",
      " [ 22 103]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[703 423]\n",
      " [ 29  96]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[654 472]\n",
      " [ 18 107]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.601918       0.607595    0.605678  0.606635  0.601867  14.348313   \n",
      "1      0.619504       0.606742    0.620690  0.613636  0.619535  13.714452   \n",
      "2      0.594724       0.571192    0.581788  0.576441  0.594085  14.607620   \n",
      "3      0.603517       0.622867    0.570312  0.595432  0.604305  14.290689   \n",
      "4      0.613110       0.606688    0.616505  0.611557  0.613150  13.944947   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.598055       0.596645        0.574919     0.591290  ...   \n",
      "1         0.618380       0.637380        0.657005     0.628659  ...   \n",
      "2         0.606383       0.619010        0.600946     0.629752  ...   \n",
      "3         0.638298       0.586262        0.582090     0.568882  ...   \n",
      "4         0.609795       0.612620        0.602236     0.615008  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.776            0.291729             0.691286   \n",
      "1                   0.776            0.302652             0.701943   \n",
      "2                   0.824            0.308383             0.716618   \n",
      "3                   0.768            0.298137             0.696167   \n",
      "4                   0.856            0.303977             0.718409   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0             13.570392                     0.606572       0.450958   \n",
      "1             12.878907                     0.627886       0.441983   \n",
      "2             13.311085                     0.609236       0.471694   \n",
      "3             13.022967                     0.624334       0.458853   \n",
      "4             14.117818                     0.580817       0.451423   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.022595        0.022479                   0.023964       0.001878  \n",
      "1       0.022742        0.022308                   0.022940       0.002253  \n",
      "2       0.023157        0.023082                   0.025139       0.001543  \n",
      "3       0.022433        0.022464                   0.025307       0.001731  \n",
      "4       0.022667        0.022567                   0.023148       0.001468  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall   Val F1   Val AUC   Val Loss  \\\n",
      "mean      0.606555       0.603017    0.598995  0.60074  0.606588  14.181204   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.614182       0.610383        0.603439     0.606718  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                     0.8            0.300976             0.704885   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean             13.380234                     0.609769       0.454982   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean       0.022719         0.02258                     0.0241       0.001775  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.606554756195044\t0.6030166710019651\t0.5989945528118179\t0.600740363997987\t0.6065883411528651\t14.181203995302528\t0.6141821294939123\t0.6103833865814696\t0.6034391487793824\t0.6067182333319157\t0.6048972358468105\t0.6104326749481681\t14.043206168699161\t0.6141471165644203\t0.6287769784172662\t0.18541470604113688\t0.8\t0.3009757163230908\t0.7048845470692717\t13.380233919988815\t0.6097690941385434\t0.4549820899963379\t0.02271871566772461\t0.02257986068725586\t0.02409963607788086\t0.00177459716796875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Tv2V9sh7RA1"
   },
   "source": [
    "## Using Class Weight Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KEMdW6qk7SC6",
    "outputId": "9404e573-b674-480a-a1c1-2a8c3f1d9026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[684 442]\n",
      " [ 28  97]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[709 417]\n",
      " [ 28  97]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[691 435]\n",
      " [ 22 103]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[703 423]\n",
      " [ 29  96]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[657 469]\n",
      " [ 18 107]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.604317       0.610845    0.604101  0.607454  0.604320  14.261877   \n",
      "1      0.619504       0.606742    0.620690  0.613636  0.619535  13.714452   \n",
      "2      0.597122       0.574790    0.576728  0.575758  0.596115  14.521184   \n",
      "3      0.601918       0.620748    0.570312  0.594463  0.602669  14.348313   \n",
      "4      0.613110       0.607029    0.614887  0.610932  0.613131  13.944947   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.604538       0.595847        0.574225     0.589615  ...   \n",
      "1         0.618380       0.637380        0.656000     0.631741  ...   \n",
      "2         0.615502       0.623003        0.606400     0.626446  ...   \n",
      "3         0.635025       0.586262        0.582090     0.568882  ...   \n",
      "4         0.611374       0.612620        0.602236     0.615008  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.776            0.292169             0.691730   \n",
      "1                   0.776            0.303599             0.702831   \n",
      "2                   0.824            0.310709             0.718838   \n",
      "3                   0.768            0.298137             0.696167   \n",
      "4                   0.856            0.305278             0.719741   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0             13.541580                     0.607460       0.449615   \n",
      "1             12.821284                     0.629663       0.440566   \n",
      "2             13.167026                     0.613677       0.470115   \n",
      "3             13.022967                     0.624334       0.465504   \n",
      "4             14.031382                     0.583481       0.458804   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.022772        0.025464                   0.023155       0.001610  \n",
      "1       0.022630        0.022592                   0.023207       0.001555  \n",
      "2       0.023278        0.023188                   0.023907       0.001639  \n",
      "3       0.022601        0.022653                   0.023305       0.001536  \n",
      "4       0.023041        0.022797                   0.023222       0.001594  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "mean      0.607194       0.604031    0.597344  0.600449  0.607154  14.158154   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.616964       0.611022         0.60419     0.606338  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                     0.8            0.301978             0.705861   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean             13.316848                     0.611723       0.456921   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean       0.022864        0.023339                   0.023359       0.001587  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.6071942446043166\t0.6040307674738508\t0.5973436664186138\t0.6004486714527262\t0.6071536959176569\t14.158154496732347\t0.6169637254166999\t0.6110223642172523\t0.6041902192626296\t0.6063384007516355\t0.6051371078440542\t0.6109930002373544\t14.020175080271608\t0.6156475997230731\t0.6305355715427658\t0.1861727297674361\t0.8\t0.30197835353294405\t0.7058614564831261\t13.316847798920822\t0.6117229129662521\t0.45692081451416017\t0.022864294052124024\t0.023338794708251953\t0.023359251022338868\t0.001586771011352539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCXK3bPlS6L4"
   },
   "source": [
    "## With hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gEC23mOL7b3N",
    "outputId": "69eafe54-f7df-44c4-f5a7-a96d24f82cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[731 395]\n",
      " [ 37  88]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[755 371]\n",
      " [ 36  89]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[737 389]\n",
      " [ 29  96]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[763 363]\n",
      " [ 34  91]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[703 423]\n",
      " [ 22 103]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.609912       0.622896    0.583596  0.602606  0.610275  14.060194   \n",
      "1      0.617906       0.609715    0.597701  0.603648  0.617386  13.772075   \n",
      "2      0.609912       0.592267    0.568297  0.580034  0.607857  14.060194   \n",
      "3      0.623501       0.660952    0.542188  0.595708  0.625431  13.570392   \n",
      "4      0.629097       0.627907    0.611650  0.619672  0.628890  13.368709   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.636953       0.607827        0.593310     0.564489  ...   \n",
      "1         0.637072       0.645367        0.677643     0.602465  ...   \n",
      "2         0.647416       0.630192        0.618333     0.613223  ...   \n",
      "3         0.708674       0.600639        0.606171     0.541329  ...   \n",
      "4         0.646130       0.625399        0.625874     0.584013  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.704            0.289474             0.676600   \n",
      "1                   0.712            0.304274             0.691258   \n",
      "2                   0.768            0.314754             0.711265   \n",
      "3                   0.728            0.314335             0.702810   \n",
      "4                   0.824            0.316436             0.724167   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0             12.446729                     0.649201       0.817236   \n",
      "1             11.726432                     0.670515       0.817451   \n",
      "2             12.043363                     0.654529       0.840501   \n",
      "3             11.438314                     0.677620       0.897769   \n",
      "4             12.821284                     0.624334       0.884372   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.040881        0.043369                   0.041844       0.001591  \n",
      "1       0.040846        0.040550                   0.041579       0.001658  \n",
      "2       0.041685        0.040537                   0.041437       0.002037  \n",
      "3       0.040227        0.040186                   0.041049       0.001606  \n",
      "4       0.047709        0.045986                   0.043083       0.001474  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "mean      0.618066       0.622747    0.580686  0.600334  0.617968  13.766313   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.655249       0.621885        0.624266     0.581104  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                  0.7472            0.307855              0.70122   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean             12.095224                      0.65524       0.851466   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean        0.04227        0.042126                   0.041798       0.001673  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.6180655475619504\t0.6227474717596788\t0.5806864290652008\t0.6003337993596051\t0.6179677054452586\t13.76631302103931\t0.6552489818253163\t0.6218849840255591\t0.6242661796418669\t0.5811039291837491\t0.601658456136006\t0.6213818349338007\t13.628646577003243\t0.6616597406838522\t0.6644284572342126\t0.19397380826106914\t0.7472\t0.3078545198427719\t0.7012198934280639\t12.095224374701342\t0.6552397868561279\t0.8514657020568848\t0.04226961135864258\t0.04212555885314941\t0.04179840087890625\t0.001673126220703125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced', \n",
    "                            max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200)\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "pboPJG6anvIY"
   },
   "outputs": [],
   "source": [
    "# # define the hyperparameter grid to search over\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# # n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# n_estimators = [50,100,200]\n",
    "# # Number of features to consider at every split\n",
    "# # max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [2,4,6,8,None]\n",
    "# # max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# # max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': n_estimators,\n",
    "#     # 'max_features': max_features,\n",
    "#     'max_depth': max_depth,\n",
    "#     'min_samples_split': min_samples_split,\n",
    "#     'min_samples_leaf': min_samples_leaf,\n",
    "#     'bootstrap': bootstrap\n",
    "# }\n",
    "\n",
    "# # create a random forest classifier object\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # create a grid search object\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', verbose=2)\n",
    "\n",
    "# # fit the grid search object to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # print the best hyperparameters and corresponding f1 score\n",
    "# print('Best hyperparameters:', grid_search.best_params_)\n",
    "# print('Best F1 score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "R2qrjWIpURxx"
   },
   "outputs": [],
   "source": [
    "# data_testing_01\n",
    "# Best hyperparameters: {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "\n",
    "\n",
    "# data_full_1\n",
    "# Best hyperparameters: {'bootstrap': False, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eDDRgTPamPN"
   },
   "source": [
    "## Hyperparameter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2zXjRJ9WUYYL",
    "outputId": "e5b20e90-b70c-4ddb-b345-96277798cd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1027   99]\n",
      " [  83   42]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1018  108]\n",
      " [  71   54]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1042   84]\n",
      " [  72   53]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[946 180]\n",
      " [ 58  67]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1022  104]\n",
      " [  64   61]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.652278       0.835017    0.391167  0.532760  0.655875  12.533165   \n",
      "1      0.667466       0.824916    0.402299  0.540839  0.660651  11.985739   \n",
      "2      0.700240       0.886525    0.421585  0.571429  0.686476  10.804452   \n",
      "3      0.643485       0.728774    0.482812  0.580827  0.647298  12.850095   \n",
      "4      0.686651       0.848765    0.444984  0.583864  0.683787  11.294254   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.920583       0.676518        0.809677     0.420436  ...   \n",
      "1         0.919003       0.674121        0.841360     0.457627  ...   \n",
      "2         0.951368       0.674121        0.792285     0.441322  ...   \n",
      "3         0.811784       0.670927        0.749392     0.499190  ...   \n",
      "4         0.922591       0.678115        0.838710     0.424144  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.336            0.315789             0.624039   \n",
      "1                   0.432            0.376307             0.668043   \n",
      "2                   0.424            0.404580             0.674700   \n",
      "3                   0.536            0.360215             0.688071   \n",
      "4                   0.488            0.420690             0.697819   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0              5.243761                     0.912078       0.218510   \n",
      "1              5.157325                     0.904085       0.202341   \n",
      "2              4.494652                     0.925400       0.198522   \n",
      "3              6.857226                     0.840142       0.273370   \n",
      "4              4.840395                     0.907638       0.198514   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.011194        0.010983                   0.010392       0.002047  \n",
      "1       0.010436        0.010780                   0.010290       0.001846  \n",
      "2       0.010879        0.010770                   0.010348       0.001495  \n",
      "3       0.011347        0.010693                   0.010201       0.001591  \n",
      "4       0.011075        0.010777                   0.010331       0.001632  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "mean      0.670024       0.824799     0.42857  0.561944  0.666818  11.893541   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.905066        0.67476        0.806285     0.448544  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                  0.4432            0.375516             0.670534   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean              5.318672                     0.897869       0.218251   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean       0.010986        0.010801                   0.010312       0.001722  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.6700239808153478\t0.8247992999264241\t0.42856950439526437\t0.5619438165401875\t0.6668176684794508\t11.893541262212278\t0.9050658325636372\t0.6747603833865815\t0.8062846928216116\t0.44854362541810777\t0.575153682318944\t0.671112916327929\t11.722824009623407\t0.8936822072377503\t0.8524380495603516\t0.3318038036106386\t0.44320000000000004\t0.37551619110017603\t0.6705342806394317\t5.318671795068765\t0.8978685612788633\t0.21825146675109863\t0.010986232757568359\t0.010800600051879883\t0.010312414169311524\t0.0017221927642822265\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced', \n",
    "                            bootstrap = False, max_depth= 6, min_samples_leaf = 2, min_samples_split = 2, n_estimators = 100\n",
    "                              # bootstrap = False, max_depth= 10, min_samples_leaf = 4, min_samples_split = 2, n_estimators = 100\n",
    ")\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
