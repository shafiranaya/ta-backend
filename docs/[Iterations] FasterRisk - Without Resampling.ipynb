{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccdfe217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasterrisk in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (0.1.5)\n",
      "Requirement already satisfied: pandas==1.5.2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.5.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.3 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.23.3)\n",
      "Requirement already satisfied: scikit-learn==1.2.0 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (2.28.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.5.2->fasterrisk) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.5.2->fasterrisk) (2.8.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (1.10.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.2->fasterrisk) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %conda create -n FasterRisk python=3.9 # create a virtual environment\n",
    "# %conda activate FasterRisk # activate the virtual environment\n",
    "%pip install fasterrisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c31a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cba10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasterrisk.fasterrisk import RiskScoreOptimizer, RiskScoreClassifier\n",
    "from fasterrisk.utils import download_file_from_google_drive,  compute_logisticLoss_from_X_y_beta0_betas, get_all_product_booleans, get_support_indices, isEqual_upTo_8decimal, isEqual_upTo_16decimal, get_all_product_booleans\n",
    "\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, log_loss, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d56915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For resampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN, ADASYN, RandomOverSampler\n",
    "# from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "# from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Ensemble Classifiers\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, cross_val_score, train_test_split, KFold, cross_validate\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, log_loss, classification_report, confusion_matrix\n",
    "\n",
    "# from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b61decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calculation_table(risk_score_model):\n",
    "    assert risk_score_model.featureNames is not None, \"please pass the featureNames to the model by using the function .reset_featureNames(featureNames)\"\n",
    "\n",
    "    nonzero_indices = get_support_indices(risk_score_model.coefficients)\n",
    "\n",
    "    max_feature_length = max([len(featureName) for featureName in risk_score_model.featureNames])\n",
    "    row_score_template = '{0}. {1:>%d}     {2:>2} point(s) | + ...' % (max_feature_length)\n",
    "\n",
    "    print(\"The Risk Score is:\")\n",
    "    for count, feature_i in enumerate(nonzero_indices):\n",
    "        row_score_str = row_score_template.format(count+1, risk_score_model.featureNames[feature_i], int(risk_score_model.coefficients[feature_i]))\n",
    "        if count == 0:\n",
    "            row_score_str = row_score_str.replace(\"+\", \" \")\n",
    "\n",
    "        print(row_score_str)\n",
    "\n",
    "    final_score_str = ' ' * (14+max_feature_length) + 'SCORE | =    '\n",
    "    print(final_score_str)\n",
    "    \n",
    "    \n",
    "    print(\"###\")\n",
    "    feature_names_list = []\n",
    "    coefficients_list = []\n",
    "    for count, feature_i in enumerate(nonzero_indices):\n",
    "        feature_names_list.append(risk_score_model.featureNames[feature_i])\n",
    "        coefficients_list.append(int(risk_score_model.coefficients[feature_i]))\n",
    "    \n",
    "    print(\"feature names: \", feature_names_list)\n",
    "    print(\"coefficients: \", coefficients_list)\n",
    "    print(len(feature_names_list) == len(coefficients_list))\n",
    "\n",
    "def print_classification_metrics(risk_score_model, X, y):\n",
    "    start = time.time()\n",
    "    y_pred = risk_score_model.predict(X)\n",
    "    stop = time.time()\n",
    "    print(f\"Predict time: {stop-start} s\")\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    # Compute the precision\n",
    "    precision = precision_score(y, y_pred)\n",
    "    print(\"Precision: {:.3f}\".format(precision))\n",
    "    # Compute the recall or sensitivity\n",
    "    recall = recall_score(y, y_pred)\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(\"F1 score: {:.3f}\".format(f1))\n",
    "    # Compute the roc auc score\n",
    "    auc = roc_auc_score(y,y_pred)\n",
    "    print(\"AUC score: {:.3f}\".format(auc))\n",
    "    # Compute the log lossscore\n",
    "    loss = log_loss(y,y_pred)\n",
    "    print(\"Log loss: {:.3f}\".format(loss))\n",
    "\n",
    "    # Assume y and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr = tp / (tp + fn) # Sensitivity\n",
    "    tnr = tn / (tn + fp) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    print(\"G-mean: {:.3f}\".format(gmean))\n",
    "\n",
    "    print(\"Specificity: {:.3f}\".format(tnr))\n",
    "\n",
    "    # Print classification report and G-mean\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "    print(\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\".format(accuracy,precision,recall,f1,auc,loss,tnr))\n",
    "\n",
    "    print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be67c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(dataframe, sparsity=5, parent_size=10, model_index=0, random_state=0):\n",
    "    ### DATAFRAME FORMATTING ###\n",
    "    df = dataframe.copy()\n",
    "    print(df['label'].value_counts())\n",
    "    target_col = 'label'\n",
    "    df[target_col] = df[target_col].apply(lambda x: 1 if x==1 else -1) \n",
    "#     ({1: 1, 0: -1})  \n",
    "    print(df['label'].value_counts())\n",
    "    # Identify columns with boolean data type\n",
    "    bool_columns = df.select_dtypes(include=['bool']).columns\n",
    "    # Convert boolean columns to integer\n",
    "    df[bool_columns] = df[bool_columns].astype(int)\n",
    "    print(df['label'].value_counts())\n",
    "\n",
    "    ### SPLITTING THE DATA ###\n",
    "    X = df.drop(['label','account_id'], axis=1)\n",
    "    y = df['label']\n",
    "\n",
    "    # Separate minority and majority classes\n",
    "    minority_class = df[df['label'] == 1]\n",
    "    majority_class = df[df['label'] == -1]\n",
    "    print(len(majority_class), len(minority_class))\n",
    "    # # Undersample majority class\n",
    "    # undersampled_majority_class = resample(majority_class, \n",
    "    #                                       replace=False, \n",
    "    #                                       n_samples=len(minority_class),\n",
    "    #                                       )\n",
    "\n",
    "    # # Combine minority class with undersampled majority class\n",
    "    # undersampled_data = pd.concat([minority_class, undersampled_majority_class])\n",
    "\n",
    "    # # Split the undersampled data into training, validation, and test sets\n",
    "    # X_undersampled = undersampled_data.drop(['label','account_id'], axis=1)\n",
    "    # y_undersampled = undersampled_data['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=random_state)\n",
    "\n",
    "#     # Print the number of examples in each set\n",
    "#     print(\"Number of examples in the training set: \", len(X_train))\n",
    "#     print(\"Number of examples in the validation set: \", len(X_val))\n",
    "#     print(\"Number of examples in the test set: \", len(X_test))\n",
    "    # Calculate the desired number of samples for each class based on the proportion in the test dataset\n",
    "    desired_majority_samples = int(len(X_test) * 0.90)\n",
    "    desired_minority_samples = int(len(X_test) * 0.10)\n",
    "\n",
    "    print(\"desired\",desired_majority_samples, desired_minority_samples)\n",
    "    # Resample the majority class in the test dataset\n",
    "    resampled_majority_class = resample(majority_class,\n",
    "                                        replace=True,\n",
    "                                        n_samples=desired_majority_samples,\n",
    "                                        random_state=random_state\n",
    "                                        )\n",
    "\n",
    "    # Sample the minority class in the test dataset\n",
    "    sampled_minority_class = resample(minority_class,\n",
    "                                      replace=True,\n",
    "                                      n_samples=desired_minority_samples,\n",
    "                                    random_state=random_state\n",
    "\n",
    "                                      )\n",
    "\n",
    "    test_imbalanced = pd.concat([resampled_majority_class, sampled_minority_class])\n",
    "    X_test_imbalanced = test_imbalanced.drop(['label', 'account_id'], axis=1)\n",
    "    y_test_imbalanced= test_imbalanced['label']\n",
    "\n",
    "#     print(\"Number of examples in the test imbalanced set: \", len(X_test_imbalanced))\n",
    "#     # Print the number of examples in each class in the imbalanced test dataset\n",
    "#     print(\"Number of examples in the imbalanced test dataset (label -1):\", len(y_test_imbalanced[y_test_imbalanced == -1]))\n",
    "#     print(\"Number of examples in the imbalanced test dataset (label 1):\", len(y_test_imbalanced[y_test_imbalanced == 1]))\n",
    "      \n",
    "    ### CONVERT TO NUMPY ###\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_val = np.asarray(X_val)\n",
    "    y_val = np.asarray(y_val)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "    X_test_imbalanced = np.asarray(X_test_imbalanced)\n",
    "    y_test_imbalanced = np.asarray(y_test_imbalanced)\n",
    "\n",
    "    ### MODELLING ###\n",
    "    RiskScoreOptimizer_m = RiskScoreOptimizer(X = X_train, y = y_train, k = sparsity, parent_size = parent_size)\n",
    "    start_training_time = time.time()\n",
    "    RiskScoreOptimizer_m.optimize()\n",
    "    stop_training_time = time.time()\n",
    "    training_time = stop_training_time - start_training_time\n",
    "\n",
    "    multipliers, sparseDiversePool_beta0_integer, sparseDiversePool_betas_integer = RiskScoreOptimizer_m.get_models()\n",
    "    print(\"We generate {} risk score models from the sparse diverse pool\".format(len(multipliers)))\n",
    "    \n",
    "#     model_index = 0 # first model\n",
    "    multiplier = multipliers[model_index]\n",
    "    intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "    coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "    model = RiskScoreClassifier(multiplier, intercept, coefficients)\n",
    "    X_featureNames = list(X.columns)\n",
    "\n",
    "    model.reset_featureNames(X_featureNames)\n",
    "    model.print_model_card()\n",
    "    ### RESULTS ###\n",
    "    ## Val\n",
    "    start_pred_val = time.time()\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    stop_pred_val = time.time()\n",
    "    pred_val_time = stop_pred_val - start_pred_val\n",
    "\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    precision_val = precision_score(y_val, y_pred_val)\n",
    "    recall_val = recall_score(y_val, y_pred_val)\n",
    "    f1_val = f1_score(y_val, y_pred_val)\n",
    "    auc_val = roc_auc_score(y_val,y_pred_val)\n",
    "    loss_val = log_loss(y_val,y_pred_val)\n",
    "    # Assume y_val and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_val = tp_val / (tp_val + fn_val) # Sensitivity\n",
    "    tnr_val = tn_val / (tn_val + fp_val) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_val = np.sqrt(tpr_val * tnr_val) \n",
    "    ## Test\n",
    "    start_pred_test = time.time()\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    stop_pred_test = time.time()\n",
    "    pred_test_time = stop_pred_test - start_pred_test\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    auc_test = roc_auc_score(y_test,y_pred_test)\n",
    "    loss_test = log_loss(y_test,y_pred_test)\n",
    "    # Assume y_test and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test = tp_test / (tp_test + fn_test) # Sensitivity\n",
    "    tnr_test = tn_test / (tn_test + fp_test) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test = np.sqrt(tpr_test * tnr_test)\n",
    "    \n",
    "    ## test imbalanced\n",
    "    start_pred_test_imbalanced = time.time()\n",
    "    y_pred_test_imbalanced = model.predict(X_test_imbalanced)\n",
    "    stop_pred_test_imbalanced = time.time()\n",
    "    pred_test_imbalanced_time = stop_pred_test_imbalanced - start_pred_test_imbalanced\n",
    "\n",
    "    accuracy_test_imbalanced = accuracy_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    precision_test_imbalanced = precision_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    recall_test_imbalanced = recall_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    f1_test_imbalanced = f1_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    auc_test_imbalanced = roc_auc_score(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    loss_test_imbalanced = log_loss(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    # Assume y_test_imbalanced and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test_imbalanced, fp_test_imbalanced, fn_test_imbalanced, tp_test_imbalanced = confusion_matrix(y_test_imbalanced, y_pred_test_imbalanced).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test_imbalanced = tp_test_imbalanced / (tp_test_imbalanced + fn_test_imbalanced) # Sensitivity\n",
    "    tnr_test_imbalanced = tn_test_imbalanced / (tn_test_imbalanced + fp_test_imbalanced) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test_imbalanced = np.sqrt(tpr_test_imbalanced * tnr_test_imbalanced) \n",
    "    print(confusion_matrix(y_test_imbalanced, y_pred_test_imbalanced))\n",
    "    val_results = [accuracy_val, precision_val, recall_val, f1_val, auc_val, loss_val, tnr_val]\n",
    "    test_results = [accuracy_test, precision_test, recall_test, f1_test, auc_test, loss_test, tnr_test]\n",
    "    test_imbalanced_results = [accuracy_test_imbalanced, precision_test_imbalanced, recall_test_imbalanced, f1_test_imbalanced, auc_test_imbalanced, loss_test_imbalanced, tnr_test_imbalanced]\n",
    "\n",
    "    time_results = [training_time, pred_val_time, pred_test_time, pred_test_imbalanced_time]\n",
    "    return val_results, test_results, test_imbalanced_results, time_results\n",
    "    # return accuracy, precision, recall, f1, auc, loss, tnr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ff00f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iterations(df,sparsity,parent_size,model_index, iterations=5):\n",
    "    results = []\n",
    "    random_state = [12,23,34,45,56]\n",
    "    for i in range(len(random_state)):\n",
    "        val_results, test_results, test_imbalanced_results, time_results = train_and_evaluate_model(df,sparsity,parent_size,model_index, random_state[i])\n",
    "        concatted_results = val_results + test_results + test_imbalanced_results + time_results\n",
    "    \n",
    "        results.append(concatted_results)\n",
    "\n",
    "    columns = ['Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1', 'Val AUC', 'Val Loss', 'Val Specificity',\n",
    "               'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test AUC', 'Test Loss', 'Test Specificity',\n",
    "               'Test Imbalanced Accuracy', 'Test Imbalanced Precision', 'Test Imbalanced Recall', 'Test Imbalanced F1', 'Test Imbalanced AUC', 'Test Imbalanced Loss', 'Test Imbalanced Specificity',\n",
    "               'Training Time', 'Pred Val Time', 'Pred Test Time', 'Pred Test Imbalanced Time'\n",
    "               ]\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    print(df)\n",
    "    stats = df.describe().loc[['mean']]\n",
    "    # stats = df.describe()\n",
    "    print(stats)\n",
    "    return stats.to_csv(sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37490b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name ='data_a'\n",
    "dataset_file_path = '../dataset/' + dataset_name + '.csv'\n",
    "# train_data_file_path = \"../dataset/\"+ dataset_name + \"_train.csv\"\n",
    "# test_data_file_path = \"../dataset/\"+ dataset_name + \"_test.csv\"\n",
    "# val_data_file_path = \"../dataset/\"+ dataset_name + \"_val.csv\"\n",
    "# test_imbalanced_data_file_path = \"../dataset/\"+ dataset_name + \"_test_imbalanced.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3739e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'label'\n",
    "\n",
    "df = pd.read_csv(dataset_file_path)\n",
    "df[target_col] = df[target_col].map({1: 1, 0: -1})  \n",
    "# Identify columns with boolean data type\n",
    "bool_columns = df.select_dtypes(include=['bool']).columns\n",
    "# Convert boolean columns to integer\n",
    "df[bool_columns] = df[bool_columns].astype(int)\n",
    "\n",
    "\n",
    "# data = np.asarray(df)\n",
    "# X, y = data[:, :-1], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a97c6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate_model(df,5,10,0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecebca6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ad5d3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "desired 12878 1430\n",
      "(42926, 50)\n",
      "We generate 50 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.                              is_email_verified     -1 point(s) |   ...\n",
      "2.                               is_reseller_flag      2 point(s) | + ...\n",
      "3.              order_count_with_promo_category_0     -5 point(s) | + ...\n",
      "4.                        similar_name_category_0      3 point(s) | + ...\n",
      "5.                        similar_name_category_1      2 point(s) | + ...\n",
      "                                                            SCORE | =    \n",
      "SCORE |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |\n",
      "RISK  |   0.3% |   0.6% |   1.1% |   2.1% |   3.9% |   7.1% |  12.7% |\n",
      "SCORE |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |   7.0  |\n",
      "RISK  |  21.7% |  34.5% |  50.0% |  65.5% |  78.3% |  87.3% |  92.9% |\n",
      "[[12878     0]\n",
      " [ 1404    26]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "desired 12878 1430\n",
      "(42926, 50)\n",
      "We generate 50 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.                              is_email_verified     -1 point(s) |   ...\n",
      "2.                               is_reseller_flag      2 point(s) | + ...\n",
      "3.              order_count_with_promo_category_0     -5 point(s) | + ...\n",
      "4.                        similar_name_category_0      3 point(s) | + ...\n",
      "5.                        similar_name_category_1      2 point(s) | + ...\n",
      "                                                            SCORE | =    \n",
      "SCORE |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |\n",
      "RISK  |   0.3% |   0.5% |   1.0% |   2.0% |   3.7% |   6.9% |  12.4% |\n",
      "SCORE |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |   7.0  |\n",
      "RISK  |  21.4% |  34.3% |  50.0% |  65.7% |  78.6% |  87.6% |  93.1% |\n",
      "[[12877     1]\n",
      " [ 1413    17]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "desired 12878 1430\n",
      "(42926, 50)\n",
      "We generate 50 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.                              is_email_verified     -1 point(s) |   ...\n",
      "2.                               is_reseller_flag      2 point(s) | + ...\n",
      "3.              order_count_with_promo_category_0     -4 point(s) | + ...\n",
      "4.                        similar_name_category_0      2 point(s) | + ...\n",
      "5.                        similar_name_category_1      2 point(s) | + ...\n",
      "                                                            SCORE | =    \n",
      "SCORE |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |\n",
      "RISK  |   0.4% |   0.9% |   2.0% |   4.3% |   8.9% |  17.5% |\n",
      "SCORE |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |  31.5% |  50.0% |  68.5% |  82.5% |  91.1% |  95.7% |\n",
      "[[12874     4]\n",
      " [ 1407    23]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "desired 12878 1430\n",
      "(42926, 50)\n",
      "We generate 50 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.                              is_email_verified     -1 point(s) |   ...\n",
      "2.                               is_reseller_flag      2 point(s) | + ...\n",
      "3.              order_count_with_promo_category_0     -4 point(s) | + ...\n",
      "4.                        similar_name_category_0      2 point(s) | + ...\n",
      "5.                        similar_name_category_1      2 point(s) | + ...\n",
      "                                                            SCORE | =    \n",
      "SCORE |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |\n",
      "RISK  |   0.4% |   0.9% |   1.9% |   4.0% |   8.5% |  17.0% |\n",
      "SCORE |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |  31.2% |  50.0% |  68.8% |  83.0% |  91.5% |  96.0% |\n",
      "[[12877     1]\n",
      " [ 1408    22]]\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "-1    68416\n",
      " 1     3128\n",
      "Name: label, dtype: int64\n",
      "68416 3128\n",
      "desired 12878 1430\n",
      "(42926, 50)\n",
      "We generate 50 risk score models from the sparse diverse pool\n",
      "The Risk Score is:\n",
      "1.                              is_email_verified     -1 point(s) |   ...\n",
      "2.                               is_reseller_flag      2 point(s) | + ...\n",
      "3.              order_count_with_promo_category_0     -5 point(s) | + ...\n",
      "4.                        similar_name_category_0      2 point(s) | + ...\n",
      "5.                     similar_email_category_> 5      4 point(s) | + ...\n",
      "                                                            SCORE | =    \n",
      "SCORE |  -6.0  |  -5.0  |  -4.0  |  -3.0  |  -2.0  |  -1.0  |   0.0  |   1.0  |\n",
      "RISK  |   0.6% |   1.1% |   2.0% |   3.8% |   7.0% |  12.5% |  21.5% |  34.3% |\n",
      "SCORE |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |   7.0  |   8.0  |\n",
      "RISK  |  50.0% |  65.7% |  78.5% |  87.5% |  93.0% |  96.2% |  98.0% |\n",
      "[[12877     1]\n",
      " [ 1413    17]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC  Val Loss  \\\n",
      "0      0.957509       0.916667    0.017799  0.034921  0.508863  1.531522   \n",
      "1      0.956391       0.923077    0.018898  0.037037  0.509412  1.571825   \n",
      "2      0.956181       0.857143    0.018838  0.036866  0.509346  1.579382   \n",
      "3      0.954993       0.833333    0.015337  0.030120  0.507595  1.622204   \n",
      "4      0.957300       0.785714    0.017771  0.034755  0.508776  1.539078   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.999927       0.957160        0.900000     0.014493  ...   \n",
      "1         0.999927       0.954714        0.916667     0.016717  ...   \n",
      "2         0.999854       0.959047        0.833333     0.025084  ...   \n",
      "3         0.999854       0.957439        0.600000     0.014706  ...   \n",
      "4         0.999781       0.959117        0.857143     0.020168  ...   \n",
      "\n",
      "   Test Imbalanced Precision  Test Imbalanced Recall  Test Imbalanced F1  \\\n",
      "0                   1.000000                0.018182            0.035714   \n",
      "1                   0.944444                0.011888            0.023481   \n",
      "2                   0.851852                0.016084            0.031572   \n",
      "3                   0.956522                0.015385            0.030282   \n",
      "4                   0.944444                0.011888            0.023481   \n",
      "\n",
      "   Test Imbalanced AUC  Test Imbalanced Loss  Test Imbalanced Specificity  \\\n",
      "0             0.509091              3.536853                     1.000000   \n",
      "1             0.505905              3.562044                     0.999922   \n",
      "2             0.507887              3.554487                     0.999689   \n",
      "3             0.507653              3.549448                     0.999922   \n",
      "4             0.505905              3.562044                     0.999922   \n",
      "\n",
      "   Training Time  Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  \n",
      "0      66.250798       0.005598        0.002939                   0.003394  \n",
      "1      67.548423       0.005783        0.004768                   0.003677  \n",
      "2      61.712088       0.009026        0.006927                   0.006627  \n",
      "3      68.224348       0.005445        0.007860                   0.007323  \n",
      "4      60.845435       0.005283        0.003411                   0.004359  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall   Val F1   Val AUC  Val Loss  \\\n",
      "mean      0.956475       0.863187    0.017729  0.03474  0.508799  1.568802   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.999868       0.957495        0.821429     0.018234  ...   \n",
      "\n",
      "      Test Imbalanced Precision  Test Imbalanced Recall  Test Imbalanced F1  \\\n",
      "mean                   0.939452                0.014685            0.028906   \n",
      "\n",
      "      Test Imbalanced AUC  Test Imbalanced Loss  Test Imbalanced Specificity  \\\n",
      "mean             0.507288              3.552975                     0.999891   \n",
      "\n",
      "      Training Time  Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  \n",
      "mean      64.916218       0.006227        0.005181                   0.005076  \n",
      "\n",
      "[1 rows x 25 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\n",
      "mean\t0.9564749458382835\t0.8631868131868133\t0.01772866322996918\t0.03473992952271761\t0.5087985276495466\t1.568801965947457\t0.9998683920691237\t0.9574952826892165\t0.8214285714285714\t0.018233528094223527\t0.03563605390661519\t0.5090218638151303\t1.5320252981522855\t0.9998101995360369\t0.9014257757897679\t0.9394524959742352\t0.014685314685314685\t0.028905901841957293\t0.5072883010761562\t3.5529751705347237\t0.999891287466998\t64.91621842384339\t0.00622706413269043\t0.005181026458740234\t0.005075979232788086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_iterations(df,5,10,0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26e7bfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>label</th>\n",
       "      <th>is_phone_number_verified</th>\n",
       "      <th>is_email_verified</th>\n",
       "      <th>is_reseller_flag</th>\n",
       "      <th>email_category_gmail</th>\n",
       "      <th>email_category_hotmail</th>\n",
       "      <th>email_category_icloud</th>\n",
       "      <th>email_category_live</th>\n",
       "      <th>email_category_others</th>\n",
       "      <th>...</th>\n",
       "      <th>similar_device_category_0</th>\n",
       "      <th>similar_device_category_1</th>\n",
       "      <th>similar_device_category_2</th>\n",
       "      <th>similar_device_category_&gt; 2</th>\n",
       "      <th>similar_birth_date_category_0</th>\n",
       "      <th>similar_birth_date_category_1</th>\n",
       "      <th>similar_birth_date_category_10-13</th>\n",
       "      <th>similar_birth_date_category_2</th>\n",
       "      <th>similar_birth_date_category_3-9</th>\n",
       "      <th>similar_birth_date_category_&gt; 13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34634632</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27536039</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29164748</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28115239</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33491857</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  label  is_phone_number_verified  is_email_verified  \\\n",
       "0    34634632      1                         1                  0   \n",
       "1    27536039     -1                         1                  0   \n",
       "2    29164748     -1                         0                  0   \n",
       "3    28115239     -1                         1                  0   \n",
       "4    33491857     -1                         1                  0   \n",
       "\n",
       "   is_reseller_flag  email_category_gmail  email_category_hotmail  \\\n",
       "0                 0                   1.0                     0.0   \n",
       "1                 0                   1.0                     0.0   \n",
       "2                 0                   0.0                     0.0   \n",
       "3                 0                   1.0                     0.0   \n",
       "4                 0                   1.0                     0.0   \n",
       "\n",
       "   email_category_icloud  email_category_live  email_category_others  ...  \\\n",
       "0                    0.0                  0.0                    0.0  ...   \n",
       "1                    0.0                  0.0                    0.0  ...   \n",
       "2                    0.0                  0.0                    0.0  ...   \n",
       "3                    0.0                  0.0                    0.0  ...   \n",
       "4                    0.0                  0.0                    0.0  ...   \n",
       "\n",
       "   similar_device_category_0  similar_device_category_1  \\\n",
       "0                        1.0                        0.0   \n",
       "1                        1.0                        0.0   \n",
       "2                        1.0                        0.0   \n",
       "3                        1.0                        0.0   \n",
       "4                        1.0                        0.0   \n",
       "\n",
       "   similar_device_category_2  similar_device_category_> 2  \\\n",
       "0                        0.0                          0.0   \n",
       "1                        0.0                          0.0   \n",
       "2                        0.0                          0.0   \n",
       "3                        0.0                          0.0   \n",
       "4                        0.0                          0.0   \n",
       "\n",
       "   similar_birth_date_category_0  similar_birth_date_category_1  \\\n",
       "0                            1.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            1.0                            0.0   \n",
       "3                            1.0                            0.0   \n",
       "4                            1.0                            0.0   \n",
       "\n",
       "   similar_birth_date_category_10-13  similar_birth_date_category_2  \\\n",
       "0                                0.0                            0.0   \n",
       "1                                0.0                            0.0   \n",
       "2                                0.0                            0.0   \n",
       "3                                0.0                            0.0   \n",
       "4                                0.0                            0.0   \n",
       "\n",
       "   similar_birth_date_category_3-9  similar_birth_date_category_> 13  \n",
       "0                              0.0                               0.0  \n",
       "1                              1.0                               0.0  \n",
       "2                              0.0                               0.0  \n",
       "3                              0.0                               0.0  \n",
       "4                              0.0                               0.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb7d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
