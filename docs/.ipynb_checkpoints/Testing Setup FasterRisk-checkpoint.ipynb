{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccdfe217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasterrisk in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (0.1.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (2.28.2)\n",
      "Requirement already satisfied: scikit-learn==1.2.0 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.2.0)\n",
      "Requirement already satisfied: pandas==1.5.2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.5.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.3 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from fasterrisk) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.5.2->fasterrisk) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from pandas==1.5.2->fasterrisk) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.2.0->fasterrisk) (1.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.2->fasterrisk) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.28.1->fasterrisk) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %conda create -n FasterRisk python=3.9 # create a virtual environment\n",
    "# %conda activate FasterRisk # activate the virtual environment\n",
    "%pip install fasterrisk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cba10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasterrisk.fasterrisk import RiskScoreOptimizer, RiskScoreClassifier\n",
    "from fasterrisk.utils import download_file_from_google_drive,  compute_logisticLoss_from_X_y_beta0_betas, get_all_product_booleans, get_support_indices, isEqual_upTo_8decimal, isEqual_upTo_16decimal, get_all_product_booleans\n",
    "\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, log_loss, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b61decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calculation_table(risk_score_model):\n",
    "    assert risk_score_model.featureNames is not None, \"please pass the featureNames to the model by using the function .reset_featureNames(featureNames)\"\n",
    "\n",
    "    nonzero_indices = get_support_indices(risk_score_model.coefficients)\n",
    "\n",
    "    max_feature_length = max([len(featureName) for featureName in risk_score_model.featureNames])\n",
    "    row_score_template = '{0}. {1:>%d}     {2:>2} point(s) | + ...' % (max_feature_length)\n",
    "\n",
    "    print(\"The Risk Score is:\")\n",
    "    for count, feature_i in enumerate(nonzero_indices):\n",
    "        row_score_str = row_score_template.format(count+1, risk_score_model.featureNames[feature_i], int(risk_score_model.coefficients[feature_i]))\n",
    "        if count == 0:\n",
    "            row_score_str = row_score_str.replace(\"+\", \" \")\n",
    "\n",
    "        print(row_score_str)\n",
    "\n",
    "    final_score_str = ' ' * (14+max_feature_length) + 'SCORE | =    '\n",
    "    print(final_score_str)\n",
    "    \n",
    "    \n",
    "    print(\"###\")\n",
    "    feature_names_list = []\n",
    "    coefficients_list = []\n",
    "    for count, feature_i in enumerate(nonzero_indices):\n",
    "        feature_names_list.append(risk_score_model.featureNames[feature_i])\n",
    "        coefficients_list.append(int(risk_score_model.coefficients[feature_i]))\n",
    "    \n",
    "    print(\"feature names: \", feature_names_list)\n",
    "    print(\"coefficients: \", coefficients_list)\n",
    "    print(len(feature_names_list) == len(coefficients_list))\n",
    "\n",
    "def print_classification_metrics(risk_score_model, X, y):\n",
    "    start = time.time()\n",
    "    y_pred = risk_score_model.predict(X)\n",
    "    stop = time.time()\n",
    "    print(f\"Predict time: {stop  start} s\")\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    # Compute the precision\n",
    "    precision = precision_score(y, y_pred)\n",
    "    print(\"Precision: {:.3f}\".format(precision))\n",
    "    # Compute the recall or sensitivity\n",
    "    recall = recall_score(y, y_pred)\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    print(\"F1 score: {:.3f}\".format(f1))\n",
    "    # Compute the roc auc score\n",
    "    auc = roc_auc_score(y,y_pred)\n",
    "    print(\"AUC score: {:.3f}\".format(auc))\n",
    "    # Compute the log lossscore\n",
    "    loss = log_loss(y,y_pred)\n",
    "    print(\"Log loss: {:.3f}\".format(loss))\n",
    "\n",
    "    # Assume y and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr = tp / (tp + fn) # Sensitivity\n",
    "    tnr = tn / (tn + fp) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    print(\"G-mean: {:.3f}\".format(gmean))\n",
    "\n",
    "    print(\"Specificity: {:.3f}\".format(tnr))\n",
    "\n",
    "    # Print classification report and G-mean\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "    print(\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\".format(accuracy,precision,recall,f1,auc,loss,tnr))\n",
    "\n",
    "    print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37490b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_file_path = \"../tests/adult_train_data.csv\"\n",
    "# test_data_file_path = \"../tests/adult_test_data.csv\"\n",
    "\n",
    "dataset_name ='data_f'\n",
    "train_data_file_path = \"../dataset/\"+ dataset_name + \"_train.csv\"\n",
    "test_data_file_path = \"../dataset/\"+ dataset_name + \"_test.csv\"\n",
    "val_data_file_path = \"../dataset/\"+ dataset_name + \"_val.csv\"\n",
    "test_imbalanced_data_file_path = \"../dataset/\"+ dataset_name + \"_test_imbalanced.csv\"\n",
    "\n",
    "# if not os.path.isfile(train_data_file_path):\n",
    "#     download_file_from_google_drive('1nuWn0QVG8tk3AN4I4f3abWLcFEP3WPec', train_data_file_path)\n",
    "# if not os.path.isfile(test_data_file_path):\n",
    "#     download_file_from_google_drive('1TyBO02LiGfHbatPWU4nzc8AndtIF-7WH', test_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19e44f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## \n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d4f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea95732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['target']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65ffc71d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3739e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'label'\n",
    "\n",
    "# Train Data\n",
    "train_df = pd.read_csv(train_data_file_path)\n",
    "train_df[target_col] = train_df[target_col].map({1: 1, 0: -1})  \n",
    "# Identify columns with boolean data type\n",
    "bool_columns = train_df.select_dtypes(include=['bool']).columns\n",
    "# Convert boolean columns to integer\n",
    "train_df[bool_columns] = train_df[bool_columns].astype(int)\n",
    "\n",
    "# Test Data \n",
    "test_df = pd.read_csv(test_data_file_path)\n",
    "test_df[target_col] = test_df[target_col].map({1: 1, 0: -1})\n",
    "# Identify columns with boolean data type\n",
    "bool_columns = test_df.select_dtypes(include=['bool']).columns\n",
    "# Convert boolean columns to integer\n",
    "test_df[bool_columns] = test_df[bool_columns].astype(int)\n",
    "\n",
    "\n",
    "# Val Data \n",
    "val_df = pd.read_csv(val_data_file_path)\n",
    "val_df[target_col] = val_df[target_col].map({1: 1, 0: -1})\n",
    "# Identify columns with boolean data type\n",
    "bool_columns = val_df.select_dtypes(include=['bool']).columns\n",
    "# Convert boolean columns to integer\n",
    "val_df[bool_columns] = val_df[bool_columns].astype(int)\n",
    "\n",
    "# Test Data  Imbalanced\n",
    "test_imbalanced_df = pd.read_csv(test_imbalanced_data_file_path)\n",
    "test_imbalanced_df[target_col] = test_imbalanced_df[target_col].map({1: 1, 0: -1})\n",
    "# Identify columns with boolean data type\n",
    "bool_columns = test_imbalanced_df.select_dtypes(include=['bool']).columns\n",
    "# Convert boolean columns to integer\n",
    "test_imbalanced_df[bool_columns] = test_imbalanced_df[bool_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a97c6340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.asarray(train_df)\n",
    "X_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
    "\n",
    "test_data = np.asarray(test_df)\n",
    "X_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
    "\n",
    "val_data = np.asarray(val_df)\n",
    "X_val, y_val = val_data[:, :-1], val_data[:, -1]\n",
    "\n",
    "test_imbalanced_data = np.asarray(test_df)\n",
    "X_test_imbalanced, y_test_imbalanced = test_imbalanced_data[:, :-1], test_imbalanced_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b852bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(train_data_file_path)\n",
    "# # convert target\n",
    "# train_df[target_col] = train_df[target_col].replace({0:-1, 1:1})\n",
    "# train_data = np.asarray(train_df)\n",
    "\n",
    "# X_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "# # Convert 0 to -1 and 1 to +1\n",
    "# y_train = np.where(y_train != 0, -1, 1)\n",
    "\n",
    "# test_df = pd.read_csv(test_data_file_path)\n",
    "# # convert target\n",
    "# test_df[target_col] = test_df[target_col].replace({0:-1, 1:1})\n",
    "\n",
    "# test_data = np.asarray(test_df)\n",
    "# X_test, y_test = test_data[:, 1:], test_data[:, 0]\n",
    "# # Convert 0 to -1 and 1 to +1\n",
    "# y_test = np.where(y_test != 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa3deba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1899\n",
       " 1    1854\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[target_col].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ec1c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0: 610\n",
      "1.0: 642\n"
     ]
    }
   ],
   "source": [
    "# Get unique values and their counts\n",
    "unique_values, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "# Create a dictionary with unique values as keys and counts as values\n",
    "value_counts = dict(zip(unique_values, counts))\n",
    "\n",
    "# Access the value counts\n",
    "for value, count in value_counts.items():\n",
    "    print(f'{value}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae8407e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_count_with_promo               float64\n",
       "price_amount                         float64\n",
       "promo_amount                         float64\n",
       "category_f_order_count_with_promo    float64\n",
       "category_f_promo_amount              float64\n",
       "similar_device_count                 float64\n",
       "similar_email_count                  float64\n",
       "label                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d85dfd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_count_with_promo</th>\n",
       "      <th>price_amount</th>\n",
       "      <th>promo_amount</th>\n",
       "      <th>category_f_order_count_with_promo</th>\n",
       "      <th>category_f_promo_amount</th>\n",
       "      <th>similar_device_count</th>\n",
       "      <th>similar_email_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_count_with_promo  price_amount  promo_amount  \\\n",
       "0                0.000000      0.000049      0.000000   \n",
       "1                0.000000      0.000003      0.000000   \n",
       "2                0.103448      0.004819      0.051818   \n",
       "3                0.000000      0.000093      0.000000   \n",
       "4                0.000000      0.001837      0.000000   \n",
       "\n",
       "   category_f_order_count_with_promo  category_f_promo_amount  \\\n",
       "0                                0.0                      0.0   \n",
       "1                                0.0                      0.0   \n",
       "2                                0.0                      0.0   \n",
       "3                                0.0                      0.0   \n",
       "4                                0.0                      0.0   \n",
       "\n",
       "   similar_device_count  similar_email_count  label  \n",
       "0                   0.0                  0.0     -1  \n",
       "1                   0.0                  0.0     -1  \n",
       "2                   0.0                  0.0      1  \n",
       "3                   0.0                  0.0      1  \n",
       "4                   0.0                  0.0     -1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437749a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69f69d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3753 entries, 0 to 3752\n",
      "Data columns (total 8 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   order_count_with_promo             3753 non-null   float64\n",
      " 1   price_amount                       3753 non-null   float64\n",
      " 2   promo_amount                       3753 non-null   float64\n",
      " 3   category_f_order_count_with_promo  3753 non-null   float64\n",
      " 4   category_f_promo_amount            3753 non-null   float64\n",
      " 5   similar_device_count               3753 non-null   float64\n",
      " 6   similar_email_count                3753 non-null   float64\n",
      " 7   label                              3753 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 234.7 KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "481e1b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_count_with_promo', 'price_amount', 'promo_amount',\n",
       "       'category_f_order_count_with_promo', 'category_f_promo_amount',\n",
       "       'similar_device_count', 'similar_email_count', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08499c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ...,  1., -1., -1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bec06e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_count_with_promo</th>\n",
       "      <th>price_amount</th>\n",
       "      <th>promo_amount</th>\n",
       "      <th>category_f_order_count_with_promo</th>\n",
       "      <th>category_f_promo_amount</th>\n",
       "      <th>similar_device_count</th>\n",
       "      <th>similar_email_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.004819</td>\n",
       "      <td>0.051818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_count_with_promo  price_amount  promo_amount  \\\n",
       "0                0.000000      0.000049      0.000000   \n",
       "1                0.000000      0.000003      0.000000   \n",
       "2                0.103448      0.004819      0.051818   \n",
       "3                0.000000      0.000093      0.000000   \n",
       "4                0.000000      0.001837      0.000000   \n",
       "\n",
       "   category_f_order_count_with_promo  category_f_promo_amount  \\\n",
       "0                                0.0                      0.0   \n",
       "1                                0.0                      0.0   \n",
       "2                                0.0                      0.0   \n",
       "3                                0.0                      0.0   \n",
       "4                                0.0                      0.0   \n",
       "\n",
       "   similar_device_count  similar_email_count  label  \n",
       "0                   0.0                  0.0     -1  \n",
       "1                   0.0                  0.0     -1  \n",
       "2                   0.0                  0.0      1  \n",
       "3                   0.0                  0.0      1  \n",
       "4                   0.0                  0.0     -1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caf6d03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_count_with_promo</th>\n",
       "      <th>price_amount</th>\n",
       "      <th>promo_amount</th>\n",
       "      <th>category_f_order_count_with_promo</th>\n",
       "      <th>category_f_promo_amount</th>\n",
       "      <th>similar_device_count</th>\n",
       "      <th>similar_email_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_count_with_promo  price_amount  promo_amount  \\\n",
       "0                0.034483      0.000061      0.010098   \n",
       "1                0.000000      0.000492      0.000000   \n",
       "2                0.000000      0.000318      0.000000   \n",
       "3                0.000000      0.018275      0.000000   \n",
       "4                0.000000      0.002064      0.000000   \n",
       "\n",
       "   category_f_order_count_with_promo  category_f_promo_amount  \\\n",
       "0                           0.058824                 0.010098   \n",
       "1                           0.000000                 0.000000   \n",
       "2                           0.000000                 0.000000   \n",
       "3                           0.000000                 0.000000   \n",
       "4                           0.000000                 0.000000   \n",
       "\n",
       "   similar_device_count  similar_email_count  label  \n",
       "0                   0.0                  0.0      1  \n",
       "1                   0.0                  0.0     -1  \n",
       "2                   0.0                  0.0     -1  \n",
       "3                   0.0                  0.0      1  \n",
       "4                   0.0                  0.0     -1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05988037",
   "metadata": {},
   "source": [
    "## Train Risk Score Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6772ac1",
   "metadata": {},
   "source": [
    "### Create RiskScoreOptimizer and Perform Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5848f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1.,  1., ..., -1.,  1.,  1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40955613",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = 5\n",
    "parent_size = 10\n",
    "RiskScoreOptimizer_m = RiskScoreOptimizer(X = X_train, y = y_train, k = sparsity, parent_size = parent_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c8b05ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization takes 0.39 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "RiskScoreOptimizer_m.optimize()\n",
    "print(\"Optimization takes {:.2f} seconds.\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92cdb18",
   "metadata": {},
   "source": [
    "## Get Risk Score Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a0c788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3753, 11)\n",
      "We generate 11 risk score models from the sparse diverse pool\n"
     ]
    }
   ],
   "source": [
    "multipliers, sparseDiversePool_beta0_integer, sparseDiversePool_betas_integer = RiskScoreOptimizer_m.get_models()\n",
    "print(\"We generate {} risk score models from the sparse diverse pool\".format(len(multipliers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f482a4b",
   "metadata": {},
   "source": [
    "### Access the first risk score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef18fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_index = 0 # first model\n",
    "multiplier = multipliers[model_index]\n",
    "intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "coefficients = sparseDiversePool_betas_integer[model_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81d247",
   "metadata": {},
   "source": [
    "### Use the first risk score model to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827f3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9685716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test are predicted to be [ 1 -1 -1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = RiskScoreClassifier_m.predict(X_test)\n",
    "print(\"y_test are predicted to be {}\".format(y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97f66531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The risk probabilities of having y_test to be +1 are [0.65198535 0.5        0.5        ... 0.5        0.5        0.5       ]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_prob = RiskScoreClassifier_m.predict_prob(X_test)\n",
    "print(\"The risk probabilities of having y_test to be +1 are {}\".format(y_test_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade6a55",
   "metadata": {},
   "source": [
    "### Print the first model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20f0e39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      promo_amount      2 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "4.           category_f_promo_amount      3 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |  50.0% |  97.8% |  99.7% |  99.9% | 100.0% | 100.0% |\n",
      "SCORE |   7.0  |   8.0  |   9.0  |  10.0  |  11.0  |  13.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      promo_amount      2 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "4.           category_f_promo_amount      3 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "###\n",
      "feature names:  ['order_count_with_promo', 'promo_amount', 'category_f_order_count_with_promo', 'category_f_promo_amount', 'similar_email_count']\n",
      "coefficients:  [3, 2, 3, 3, 2]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "X_featureNames = list(train_df.columns[:-1])\n",
    "\n",
    "RiskScoreClassifier_m.reset_featureNames(X_featureNames)\n",
    "RiskScoreClassifier_m.print_model_card()\n",
    "\n",
    "get_calculation_table(RiskScoreClassifier_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc73d9ae",
   "metadata": {},
   "source": [
    "### Print Top N Model Cards from the Pool and their performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3de6a24c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num models:  5\n",
      "Number of multipliers:  11\n",
      "---------- Model 1 ----------\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      promo_amount      2 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "4.           category_f_promo_amount      3 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |  50.0% |  97.8% |  99.7% |  99.9% | 100.0% | 100.0% |\n",
      "SCORE |   7.0  |   8.0  |   9.0  |  10.0  |  11.0  |  13.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "The logistic loss on the training set is 2440.2542665393544\n",
      "The training accuracy and AUC are 66.960% and 0.671\n",
      "The test accuracy and AUC are are 65.415% and 0.666\n",
      "\n",
      "### CLASSIFICATION REPORT - VAL ###\n",
      "Accuracy: 0.651\n",
      "Precision: 0.831\n",
      "Recall: 0.388\n",
      "F1 score: 0.529\n",
      "AUC score: 0.653\n",
      "Log loss: 12.591\n",
      "G-mean: 0.597\n",
      "Specificity: 0.919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.92      0.72       619\n",
      "         1.0       0.83      0.39      0.53       632\n",
      "\n",
      "    accuracy                           0.65      1251\n",
      "   macro avg       0.71      0.65      0.63      1251\n",
      "weighted avg       0.71      0.65      0.62      1251\n",
      "\n",
      "0.651\t0.831\t0.388\t0.529\t0.653\t12.591\t0.919\n",
      "[[569  50]\n",
      " [387 245]]\n",
      "### CLASSIFICATION REPORT - TEST ###\n",
      "Accuracy: 0.654\n",
      "Precision: 0.854\n",
      "Recall: 0.393\n",
      "F1 score: 0.538\n",
      "AUC score: 0.661\n",
      "Log loss: 12.466\n",
      "G-mean: 0.604\n",
      "Specificity: 0.930\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.93      0.72       610\n",
      "         1.0       0.85      0.39      0.54       642\n",
      "\n",
      "    accuracy                           0.65      1252\n",
      "   macro avg       0.72      0.66      0.63      1252\n",
      "weighted avg       0.73      0.65      0.63      1252\n",
      "\n",
      "0.654\t0.854\t0.393\t0.538\t0.661\t12.466\t0.930\n",
      "[[567  43]\n",
      " [390 252]]\n",
      "### CLASSIFICATION REPORT - TEST (IMBALANCED) ###\n",
      "Accuracy: 0.654\n",
      "Precision: 0.854\n",
      "Recall: 0.393\n",
      "F1 score: 0.538\n",
      "AUC score: 0.661\n",
      "Log loss: 12.466\n",
      "G-mean: 0.604\n",
      "Specificity: 0.930\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.93      0.72       610\n",
      "         1.0       0.85      0.39      0.54       642\n",
      "\n",
      "    accuracy                           0.65      1252\n",
      "   macro avg       0.72      0.66      0.63      1252\n",
      "weighted avg       0.73      0.65      0.63      1252\n",
      "\n",
      "0.654\t0.854\t0.393\t0.538\t0.661\t12.466\t0.930\n",
      "[[567  43]\n",
      " [390 252]]\n",
      "---------- Model 2 ----------\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      promo_amount      2 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "4.           category_f_promo_amount      3 point(s) | + ...\n",
      "5.              similar_device_count      3 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   3.0  |   5.0  |   6.0  |\n",
      "RISK  |  50.0% |  97.8% |  99.7% | 100.0% | 100.0% |\n",
      "SCORE |   8.0  |   9.0  |  11.0  |  12.0  |  14.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "The logistic loss on the training set is 2441.5901500407526\n",
      "The training accuracy and AUC are 67.200% and 0.670\n",
      "The test accuracy and AUC are are 65.415% and 0.664\n",
      "\n",
      "### CLASSIFICATION REPORT - VAL ###\n",
      "Accuracy: 0.652\n",
      "Precision: 0.877\n",
      "Recall: 0.362\n",
      "F1 score: 0.513\n",
      "AUC score: 0.655\n",
      "Log loss: 12.533\n",
      "G-mean: 0.586\n",
      "Specificity: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.95      0.73       619\n",
      "         1.0       0.88      0.36      0.51       632\n",
      "\n",
      "    accuracy                           0.65      1251\n",
      "   macro avg       0.74      0.66      0.62      1251\n",
      "weighted avg       0.74      0.65      0.62      1251\n",
      "\n",
      "0.652\t0.877\t0.362\t0.513\t0.655\t12.533\t0.948\n",
      "[[587  32]\n",
      " [403 229]]\n",
      "### CLASSIFICATION REPORT - TEST ###\n",
      "Accuracy: 0.654\n",
      "Precision: 0.903\n",
      "Recall: 0.364\n",
      "F1 score: 0.519\n",
      "AUC score: 0.662\n",
      "Log loss: 12.466\n",
      "G-mean: 0.591\n",
      "Specificity: 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.96      0.73       610\n",
      "         1.0       0.90      0.36      0.52       642\n",
      "\n",
      "    accuracy                           0.65      1252\n",
      "   macro avg       0.75      0.66      0.62      1252\n",
      "weighted avg       0.75      0.65      0.62      1252\n",
      "\n",
      "0.654\t0.903\t0.364\t0.519\t0.662\t12.466\t0.959\n",
      "[[585  25]\n",
      " [408 234]]\n",
      "### CLASSIFICATION REPORT - TEST (IMBALANCED) ###\n",
      "Accuracy: 0.654\n",
      "Precision: 0.903\n",
      "Recall: 0.364\n",
      "F1 score: 0.519\n",
      "AUC score: 0.662\n",
      "Log loss: 12.466\n",
      "G-mean: 0.591\n",
      "Specificity: 0.959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.59      0.96      0.73       610\n",
      "         1.0       0.90      0.36      0.52       642\n",
      "\n",
      "    accuracy                           0.65      1252\n",
      "   macro avg       0.75      0.66      0.62      1252\n",
      "weighted avg       0.75      0.65      0.62      1252\n",
      "\n",
      "0.654\t0.903\t0.364\t0.519\t0.662\t12.466\t0.959\n",
      "[[585  25]\n",
      " [408 234]]\n",
      "---------- Model 3 ----------\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      3 point(s) |   ...\n",
      "2.                      price_amount      2 point(s) | + ...\n",
      "3.                      promo_amount      2 point(s) | + ...\n",
      "4. category_f_order_count_with_promo      3 point(s) | + ...\n",
      "5.           category_f_promo_amount      3 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |\n",
      "RISK  |  50.0% |  97.8% |  99.7% |  99.9% | 100.0% | 100.0% |\n",
      "SCORE |   7.0  |   8.0  |   9.0  |  10.0  |  11.0  |  13.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "The logistic loss on the training set is 2444.01530493019\n",
      "The training accuracy and AUC are 49.427% and 0.717\n",
      "The test accuracy and AUC are are 51.278% and 0.706\n",
      "\n",
      "### CLASSIFICATION REPORT - VAL ###\n",
      "Accuracy: 0.504\n",
      "Precision: 0.505\n",
      "Recall: 0.997\n",
      "F1 score: 0.670\n",
      "AUC score: 0.499\n",
      "Log loss: 17.863\n",
      "G-mean: 0.040\n",
      "Specificity: 0.002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.33      0.00      0.00       619\n",
      "         1.0       0.50      1.00      0.67       632\n",
      "\n",
      "    accuracy                           0.50      1251\n",
      "   macro avg       0.42      0.50      0.34      1251\n",
      "weighted avg       0.42      0.50      0.34      1251\n",
      "\n",
      "0.504\t0.505\t0.997\t0.670\t0.499\t17.863\t0.002\n",
      "[[  1 618]\n",
      " [  2 630]]\n",
      "### CLASSIFICATION REPORT - TEST ###\n",
      "Accuracy: 0.513\n",
      "Precision: 0.513\n",
      "Recall: 1.000\n",
      "F1 score: 0.678\n",
      "AUC score: 0.500\n",
      "Log loss: 17.561\n",
      "G-mean: 0.000\n",
      "Specificity: 0.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       610\n",
      "         1.0       0.51      1.00      0.68       642\n",
      "\n",
      "    accuracy                           0.51      1252\n",
      "   macro avg       0.26      0.50      0.34      1252\n",
      "weighted avg       0.26      0.51      0.35      1252\n",
      "\n",
      "0.513\t0.513\t1.000\t0.678\t0.500\t17.561\t0.000\n",
      "[[  0 610]\n",
      " [  0 642]]\n",
      "### CLASSIFICATION REPORT - TEST (IMBALANCED) ###\n",
      "Accuracy: 0.513\n",
      "Precision: 0.513\n",
      "Recall: 1.000\n",
      "F1 score: 0.678\n",
      "AUC score: 0.500\n",
      "Log loss: 17.561\n",
      "G-mean: 0.000\n",
      "Specificity: 0.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       610\n",
      "         1.0       0.51      1.00      0.68       642\n",
      "\n",
      "    accuracy                           0.51      1252\n",
      "   macro avg       0.26      0.50      0.34      1252\n",
      "weighted avg       0.26      0.51      0.35      1252\n",
      "\n",
      "0.513\t0.513\t1.000\t0.678\t0.500\t17.561\t0.000\n",
      "[[  0 610]\n",
      " [  0 642]]\n",
      "---------- Model 4 ----------\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      4 point(s) |   ...\n",
      "2.                      promo_amount      4 point(s) | + ...\n",
      "3. category_f_order_count_with_promo      4 point(s) | + ...\n",
      "4.              similar_device_count      4 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   2.0  |   4.0  |   6.0  |   8.0  |\n",
      "RISK  |  50.0% |  93.2% |  99.5% | 100.0% | 100.0% |\n",
      "SCORE |  10.0  |  12.0  |  14.0  |  16.0  |  18.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "The logistic loss on the training set is 2454.333707742243\n",
      "The training accuracy and AUC are 67.253% and 0.675\n",
      "The test accuracy and AUC are are 65.895% and 0.672\n",
      "\n",
      "### CLASSIFICATION REPORT - VAL ###\n",
      "Accuracy: 0.656\n",
      "Precision: 0.824\n",
      "Recall: 0.407\n",
      "F1 score: 0.544\n",
      "AUC score: 0.659\n",
      "Log loss: 12.389\n",
      "G-mean: 0.609\n",
      "Specificity: 0.911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.91      0.72       619\n",
      "         1.0       0.82      0.41      0.54       632\n",
      "\n",
      "    accuracy                           0.66      1251\n",
      "   macro avg       0.71      0.66      0.63      1251\n",
      "weighted avg       0.71      0.66      0.63      1251\n",
      "\n",
      "0.656\t0.824\t0.407\t0.544\t0.659\t12.389\t0.911\n",
      "[[564  55]\n",
      " [375 257]]\n",
      "### CLASSIFICATION REPORT - TEST ###\n",
      "Accuracy: 0.659\n",
      "Precision: 0.852\n",
      "Recall: 0.405\n",
      "F1 score: 0.549\n",
      "AUC score: 0.666\n",
      "Log loss: 12.293\n",
      "G-mean: 0.612\n",
      "Specificity: 0.926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.93      0.73       610\n",
      "         1.0       0.85      0.40      0.55       642\n",
      "\n",
      "    accuracy                           0.66      1252\n",
      "   macro avg       0.72      0.67      0.64      1252\n",
      "weighted avg       0.73      0.66      0.64      1252\n",
      "\n",
      "0.659\t0.852\t0.405\t0.549\t0.666\t12.293\t0.926\n",
      "[[565  45]\n",
      " [382 260]]\n",
      "### CLASSIFICATION REPORT - TEST (IMBALANCED) ###\n",
      "Accuracy: 0.659\n",
      "Precision: 0.852\n",
      "Recall: 0.405\n",
      "F1 score: 0.549\n",
      "AUC score: 0.666\n",
      "Log loss: 12.293\n",
      "G-mean: 0.612\n",
      "Specificity: 0.926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.60      0.93      0.73       610\n",
      "         1.0       0.85      0.40      0.55       642\n",
      "\n",
      "    accuracy                           0.66      1252\n",
      "   macro avg       0.72      0.67      0.64      1252\n",
      "weighted avg       0.73      0.66      0.64      1252\n",
      "\n",
      "0.659\t0.852\t0.405\t0.549\t0.666\t12.293\t0.926\n",
      "[[565  45]\n",
      " [382 260]]\n",
      "---------- Model 5 ----------\n",
      "The Risk Score is:\n",
      "1.            order_count_with_promo      4 point(s) |   ...\n",
      "2.                      price_amount      1 point(s) | + ...\n",
      "3.                      promo_amount      4 point(s) | + ...\n",
      "4. category_f_order_count_with_promo      4 point(s) | + ...\n",
      "5.               similar_email_count      2 point(s) | + ...\n",
      "                                               SCORE | =    \n",
      "SCORE |   0.0  |   1.0  |   2.0  |   3.0  |   4.0  |   5.0  |   6.0  |   7.0  |\n",
      "RISK  |  50.0% |  78.8% |  93.2% |  98.1% |  99.5% |  99.9% | 100.0% | 100.0% |\n",
      "SCORE |   8.0  |   9.0  |  10.0  |  11.0  |  12.0  |  13.0  |  14.0  |  15.0  |\n",
      "RISK  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n",
      "The logistic loss on the training set is 2456.209221256445\n",
      "The training accuracy and AUC are 49.427% and 0.717\n",
      "The test accuracy and AUC are are 51.278% and 0.707\n",
      "\n",
      "### CLASSIFICATION REPORT - VAL ###\n",
      "Accuracy: 0.504\n",
      "Precision: 0.505\n",
      "Recall: 0.997\n",
      "F1 score: 0.670\n",
      "AUC score: 0.499\n",
      "Log loss: 17.863\n",
      "G-mean: 0.040\n",
      "Specificity: 0.002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.33      0.00      0.00       619\n",
      "         1.0       0.50      1.00      0.67       632\n",
      "\n",
      "    accuracy                           0.50      1251\n",
      "   macro avg       0.42      0.50      0.34      1251\n",
      "weighted avg       0.42      0.50      0.34      1251\n",
      "\n",
      "0.504\t0.505\t0.997\t0.670\t0.499\t17.863\t0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1 618]\n",
      " [  2 630]]\n",
      "### CLASSIFICATION REPORT - TEST ###\n",
      "Accuracy: 0.513\n",
      "Precision: 0.513\n",
      "Recall: 1.000\n",
      "F1 score: 0.678\n",
      "AUC score: 0.500\n",
      "Log loss: 17.561\n",
      "G-mean: 0.000\n",
      "Specificity: 0.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       610\n",
      "         1.0       0.51      1.00      0.68       642\n",
      "\n",
      "    accuracy                           0.51      1252\n",
      "   macro avg       0.26      0.50      0.34      1252\n",
      "weighted avg       0.26      0.51      0.35      1252\n",
      "\n",
      "0.513\t0.513\t1.000\t0.678\t0.500\t17.561\t0.000\n",
      "[[  0 610]\n",
      " [  0 642]]\n",
      "### CLASSIFICATION REPORT - TEST (IMBALANCED) ###\n",
      "Accuracy: 0.513\n",
      "Precision: 0.513\n",
      "Recall: 1.000\n",
      "F1 score: 0.678\n",
      "AUC score: 0.500\n",
      "Log loss: 17.561\n",
      "G-mean: 0.000\n",
      "Specificity: 0.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       610\n",
      "         1.0       0.51      1.00      0.68       642\n",
      "\n",
      "    accuracy                           0.51      1252\n",
      "   macro avg       0.26      0.50      0.34      1252\n",
      "weighted avg       0.26      0.51      0.35      1252\n",
      "\n",
      "0.513\t0.513\t1.000\t0.678\t0.500\t17.561\t0.000\n",
      "[[  0 610]\n",
      " [  0 642]]\n",
      "[2440.25, 2441.59, 2444.02, 2454.33, 2456.21]\n",
      "[0.6665, 0.6642, 0.7059, 0.6717, 0.7067]\n",
      "avg test auc:  0.59768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/shafiranaya/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "num_models = min(N, len(multipliers))\n",
    "print(\"Num models: \", num_models)\n",
    "print(\"Number of multipliers: \", len(multipliers))\n",
    "train_loss_list = []\n",
    "test_auc_list = []\n",
    "auc_list = []\n",
    "for model_index in range(num_models):\n",
    "    print(\"---------- Model {} ----------\".format(model_index+1))\n",
    "    multiplier = multipliers[model_index]\n",
    "    intercept = sparseDiversePool_beta0_integer[model_index]\n",
    "    coefficients = sparseDiversePool_betas_integer[model_index]\n",
    "\n",
    "    RiskScoreClassifier_m = RiskScoreClassifier(multiplier, intercept, coefficients)\n",
    "    RiskScoreClassifier_m.reset_featureNames(X_featureNames)\n",
    "    RiskScoreClassifier_m.print_model_card()\n",
    "\n",
    "    train_loss = RiskScoreClassifier_m.compute_logisticLoss(X_train, y_train)\n",
    "    train_acc, train_auc = RiskScoreClassifier_m.get_acc_and_auc(X_train, y_train)\n",
    "    test_acc, test_auc = RiskScoreClassifier_m.get_acc_and_auc(X_test, y_test)\n",
    "\n",
    "    print(\"The logistic loss on the training set is {}\".format(train_loss))\n",
    "    print(\"The training accuracy and AUC are {:.3f}% and {:.3f}\".format(train_acc*100, train_auc))\n",
    "    print(\"The test accuracy and AUC are are {:.3f}% and {:.3f}\\n\".format(test_acc*100, test_auc))\n",
    "    \n",
    "#     print(\"### CLASSIFICATION REPORT - TRAIN ###\")\n",
    "#     print_classification_metrics(RiskScoreClassifier_m,X_train,y_train)\n",
    "\n",
    "    print(\"### CLASSIFICATION REPORT - VAL ###\")\n",
    "    print_classification_metrics(RiskScoreClassifier_m,X_val,y_val)\n",
    "    \n",
    "    print(\"### CLASSIFICATION REPORT - TEST ###\")\n",
    "    print_classification_metrics(RiskScoreClassifier_m,X_test,y_test)\n",
    "\n",
    "    print(\"### CLASSIFICATION REPORT - TEST (IMBALANCED) ###\")\n",
    "    print_classification_metrics(RiskScoreClassifier_m,X_test_imbalanced,y_test_imbalanced)\n",
    "    \n",
    "    # TEST AUC\n",
    "    y_pred = RiskScoreClassifier_m.predict(X_test)\n",
    "    auc = roc_auc_score(y_test,y_pred)\n",
    "\n",
    "    train_loss_list.append(round(train_loss,2))\n",
    "    test_auc_list.append(round(test_auc,4))\n",
    "    auc_list.append(round(auc,4))\n",
    "\n",
    "avg_train_loss = sum(train_loss_list)/len(train_loss_list)\n",
    "avg_test_auc = sum(test_auc_list)/len(test_auc_list)\n",
    "avg_auc = sum(auc_list)/len(auc_list)\n",
    "\n",
    "print(train_loss_list)\n",
    "print(test_auc_list)\n",
    "\n",
    "# print(\"avg train loss: \", avg_train_loss)\n",
    "print(\"avg test auc: \", avg_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b57e6a",
   "metadata": {},
   "source": [
    "## Additional Tutorial on Binarizing Continuous Features\n",
    "\n",
    "If your data has continuous features, we recommend converting the continuous features to binary features as a preprocessing step to make the final model more interpretable. We use the public PIMA dataset to show how to do this as a preprocessing step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b52ea5",
   "metadata": {},
   "source": [
    "### Download the PIMA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23fbd716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pima_original_data_file_path = \"../tests/pima_original_data.csv\"\n",
    "# if not os.path.isfile(pima_original_data_file_path):\n",
    "#     download_file_from_google_drive('184JhmJiSEUiBCo8ySAD8adDn_S9rjmjM', pima_original_data_file_path)\n",
    "\n",
    "# pima_original_data_df = pd.read_csv(pima_original_data_file_path)\n",
    "# X_original_df = pima_original_data_df.drop(columns=\"Outcome\") # drop the Outcome column, which stores the y label for this binary classification problem\n",
    "\n",
    "# X_original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4cab0",
   "metadata": {},
   "source": [
    "### Convert the dataframe with continuous features to a new dataframe with binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b17b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93936b8d",
   "metadata": {},
   "source": [
    "You can then use X_binarized_df as your new design matrix and input to the FasterRisk algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fd9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
