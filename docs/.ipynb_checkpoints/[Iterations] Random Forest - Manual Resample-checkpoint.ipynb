{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "qz8knwF-VxFi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import time\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For resampling\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN, ADASYN, RandomOverSampler\n",
    "# from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "# from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Ensemble Classifiers\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, KFold\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, log_loss, classification_report, confusion_matrix\n",
    "\n",
    "# from xgboost import plot_importance, to_graphviz\n",
    "\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "p33D0MljmXB1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth, drive\n",
    "# from google.auth import default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pMBZd1lCmbN_",
    "outputId": "f4406a20-b3e0-4d44-d1cf-9f9686bc7b67"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5rNCI-nH6o9"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "rMLy4xPTWgUs"
   },
   "outputs": [],
   "source": [
    "# drive_path = '/content/drive/MyDrive/TA/Dataset/'\n",
    "drive_path = '../dataset/'\n",
    "dataset_name = 'data_c'\n",
    "df = pd.read_csv(drive_path + dataset_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "Iw8zHrcCXi_a",
    "outputId": "cb147ad5-adb4-47be-fa67-0d81883559d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>label</th>\n",
       "      <th>order_count_with_promo_category_0</th>\n",
       "      <th>order_count_with_promo_category_1</th>\n",
       "      <th>order_count_with_promo_category_&gt; 1</th>\n",
       "      <th>price_amount_category_0-280</th>\n",
       "      <th>price_amount_category_281-870</th>\n",
       "      <th>price_amount_category_871-2775</th>\n",
       "      <th>price_amount_category_&gt; 2775</th>\n",
       "      <th>promo_amount_category_0-16</th>\n",
       "      <th>promo_amount_category_16-81</th>\n",
       "      <th>promo_amount_category_&gt; 81</th>\n",
       "      <th>category_f_order_count_with_promo_category_0</th>\n",
       "      <th>category_f_order_count_with_promo_category_1</th>\n",
       "      <th>category_f_order_count_with_promo_category_2</th>\n",
       "      <th>category_f_order_count_with_promo_category_&gt; 2</th>\n",
       "      <th>category_f_promo_amount_category_0-16</th>\n",
       "      <th>category_f_promo_amount_category_17-70</th>\n",
       "      <th>category_f_promo_amount_category_&gt; 70</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34634632</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27536039</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29164748</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28115239</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33491857</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  label  order_count_with_promo_category_0  \\\n",
       "0    34634632      1                                1.0   \n",
       "1    27536039      0                                1.0   \n",
       "2    29164748      0                                1.0   \n",
       "3    28115239      0                                1.0   \n",
       "4    33491857      0                                1.0   \n",
       "\n",
       "   order_count_with_promo_category_1  order_count_with_promo_category_> 1  \\\n",
       "0                                0.0                                  0.0   \n",
       "1                                0.0                                  0.0   \n",
       "2                                0.0                                  0.0   \n",
       "3                                0.0                                  0.0   \n",
       "4                                0.0                                  0.0   \n",
       "\n",
       "   price_amount_category_0-280  price_amount_category_281-870  \\\n",
       "0                          1.0                            0.0   \n",
       "1                          1.0                            0.0   \n",
       "2                          1.0                            0.0   \n",
       "3                          1.0                            0.0   \n",
       "4                          1.0                            0.0   \n",
       "\n",
       "   price_amount_category_871-2775  price_amount_category_> 2775  \\\n",
       "0                             0.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           0.0   \n",
       "\n",
       "   promo_amount_category_0-16  promo_amount_category_16-81  \\\n",
       "0                         1.0                          0.0   \n",
       "1                         1.0                          0.0   \n",
       "2                         1.0                          0.0   \n",
       "3                         1.0                          0.0   \n",
       "4                         1.0                          0.0   \n",
       "\n",
       "   promo_amount_category_> 81  category_f_order_count_with_promo_category_0  \\\n",
       "0                         0.0                                           1.0   \n",
       "1                         0.0                                           1.0   \n",
       "2                         0.0                                           1.0   \n",
       "3                         0.0                                           1.0   \n",
       "4                         0.0                                           1.0   \n",
       "\n",
       "   category_f_order_count_with_promo_category_1  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   category_f_order_count_with_promo_category_2  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   category_f_order_count_with_promo_category_> 2  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   category_f_promo_amount_category_0-16  \\\n",
       "0                                    1.0   \n",
       "1                                    1.0   \n",
       "2                                    1.0   \n",
       "3                                    1.0   \n",
       "4                                    1.0   \n",
       "\n",
       "   category_f_promo_amount_category_17-70  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "\n",
       "   category_f_promo_amount_category_> 70  \n",
       "0                                    0.0  \n",
       "1                                    0.0  \n",
       "2                                    0.0  \n",
       "3                                    0.0  \n",
       "4                                    0.0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vw6cy2RqXlTx",
    "outputId": "d7b168c8-ed6b-473d-e0e8-68d16c05c75d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71544 entries, 0 to 71543\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   account_id                                      71544 non-null  int64  \n",
      " 1   label                                           71544 non-null  int64  \n",
      " 2   order_count_with_promo_category_0               71544 non-null  float64\n",
      " 3   order_count_with_promo_category_1               71544 non-null  float64\n",
      " 4   order_count_with_promo_category_> 1             71544 non-null  float64\n",
      " 5   price_amount_category_0-280                     71544 non-null  float64\n",
      " 6   price_amount_category_281-870                   71544 non-null  float64\n",
      " 7   price_amount_category_871-2775                  71544 non-null  float64\n",
      " 8   price_amount_category_> 2775                    71544 non-null  float64\n",
      " 9   promo_amount_category_0-16                      71544 non-null  float64\n",
      " 10  promo_amount_category_16-81                     71544 non-null  float64\n",
      " 11  promo_amount_category_> 81                      71544 non-null  float64\n",
      " 12  category_f_order_count_with_promo_category_0    71544 non-null  float64\n",
      " 13  category_f_order_count_with_promo_category_1    71544 non-null  float64\n",
      " 14  category_f_order_count_with_promo_category_2    71544 non-null  float64\n",
      " 15  category_f_order_count_with_promo_category_> 2  71544 non-null  float64\n",
      " 16  category_f_promo_amount_category_0-16           71544 non-null  float64\n",
      " 17  category_f_promo_amount_category_17-70          71544 non-null  float64\n",
      " 18  category_f_promo_amount_category_> 70           71544 non-null  float64\n",
      "dtypes: float64(17), int64(2)\n",
      "memory usage: 10.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OsjS9iuxOxH",
    "outputId": "8f33ec9a-f626-4509-dd54-e16375baebe9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68416\n",
       "1     3128\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kN1FbuDowM8A",
    "outputId": "944eff1e-6c29-42f7-a486-e786871d7d02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.956279\n",
       "1    0.043721\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGtWYlunCReA"
   },
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "vP4Nwy5eIBaA"
   },
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop(['label','account_id'], axis=1)\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T05DKwpOw7GY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "776gNRr3Kyit"
   },
   "outputs": [],
   "source": [
    "# print(len(X_train.columns))\n",
    "# print(len(X_val.columns))\n",
    "# print(len(X_test.columns))\n",
    "# print(len(X_test_imbalanced.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "TMY3TEjjLJdW"
   },
   "outputs": [],
   "source": [
    "# print(len(y_train))\n",
    "# print(len(y_val))\n",
    "# print(len(y_test))\n",
    "# print(len(y_test_imbalanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "y1NDznUibb2I"
   },
   "outputs": [],
   "source": [
    "# y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "b3OfbSfIbgB_"
   },
   "outputs": [],
   "source": [
    "# y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "ZrkESd8DbiXm"
   },
   "outputs": [],
   "source": [
    "# y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "fmoeKPjjIMi5"
   },
   "outputs": [],
   "source": [
    "# y_test_imbalanced.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b5t7El9po9b"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "FqOR2TkY0U3I"
   },
   "outputs": [],
   "source": [
    "def print_classification_metrics(y_true, y_pred):\n",
    "    # Compute the accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    # Compute the precision\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    print(\"Precision: {:.3f}\".format(precision))\n",
    "    # Compute the recall or sensitivity\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(\"F1 score: {:.3f}\".format(f1))\n",
    "    # Compute the roc auc score\n",
    "    auc = roc_auc_score(y_true,y_pred)\n",
    "    print(\"AUC score: {:.3f}\".format(auc))\n",
    "    # Compute the log lossscore\n",
    "    loss = log_loss(y_true,y_pred)\n",
    "    print(\"Log loss: {:.3f}\".format(loss))\n",
    "\n",
    "    # Assume y_true and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr = tp / (tp + fn) # Sensitivity\n",
    "    tnr = tn / (tn + fp) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean = np.sqrt(tpr * tnr)\n",
    "    print(\"G-mean: {:.3f}\".format(gmean))\n",
    "\n",
    "    print(\"Specificity: {:.3f}\".format(tnr))\n",
    "\n",
    "    # Print classification report and G-mean\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    print(\"{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\\t{:.3f}\".format(accuracy,precision,recall,f1,auc,loss,tnr))\n",
    "\n",
    "    print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "0PSidu9KOKAH"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X, y, random_state):\n",
    "    ### SPLITTING THE DATA ###\n",
    "    # Separate minority and majority classes\n",
    "    minority_class = df[df['label'] == 1]\n",
    "    majority_class = df[df['label'] == 0]\n",
    "\n",
    "    # Undersample majority class\n",
    "    start_sampling_time = time.time()\n",
    "    undersampled_majority_class = resample(majority_class, \n",
    "                                          replace=False, \n",
    "                                          n_samples=len(minority_class),\n",
    "                                           random_state=random_state\n",
    "                                          )\n",
    "    stop_sampling_time = time.time()\n",
    "    sampling_time = stop_sampling_time - start_sampling_time\n",
    "    # Combine minority class with undersampled majority class\n",
    "    undersampled_data = pd.concat([minority_class, undersampled_majority_class])\n",
    "\n",
    "    # Split the undersampled data into training, validation, and test sets\n",
    "    X_undersampled = undersampled_data.drop(['label','account_id'], axis=1)\n",
    "    y_undersampled = undersampled_data['label']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_undersampled, y_undersampled, test_size=0.2, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25,random_state=random_state)\n",
    "\n",
    "    # Print the number of examples in each set\n",
    "    print(\"Number of examples in the training set: \", len(X_train))\n",
    "    print(\"Number of examples in the validation set: \", len(X_val))\n",
    "    print(\"Number of examples in the test set: \", len(X_test))\n",
    "  \n",
    "    # Calculate the desired number of samples for each class based on the proportion in the test dataset\n",
    "    desired_majority_samples = int(len(X_test) * 0.90)\n",
    "    desired_minority_samples = int(len(X_test) * 0.10)\n",
    "\n",
    "    # Resample the majority class in the test dataset\n",
    "    resampled_majority_class = resample(majority_class,\n",
    "                                        replace=True,\n",
    "                                        n_samples=desired_majority_samples,\n",
    "                                        random_state=random_state\n",
    "                                        )\n",
    "\n",
    "    # Sample the minority class in the test dataset\n",
    "    sampled_minority_class = resample(minority_class,\n",
    "                                      replace=True,\n",
    "                                      n_samples=desired_minority_samples,\n",
    "                                      random_state=random_state\n",
    "                                      )\n",
    "\n",
    "    test_imbalanced = pd.concat([resampled_majority_class, sampled_minority_class])\n",
    "    X_test_imbalanced = test_imbalanced.drop(['label', 'account_id'], axis=1)\n",
    "    y_test_imbalanced= test_imbalanced['label']\n",
    "\n",
    "    # Print the number of examples in each class in the imbalanced test dataset\n",
    "    print(\"Number of examples in the imbalanced test dataset (label 0):\", len(y_test_imbalanced[y_test_imbalanced == 0]))\n",
    "    print(\"Number of examples in the imbalanced test dataset (label 1):\", len(y_test_imbalanced[y_test_imbalanced == 1]))\n",
    "      \n",
    "    ### MODELLING ###\n",
    "    start_training_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    stop_training_time = time.time()\n",
    "    training_time = stop_training_time - start_training_time\n",
    "\n",
    "    ### RESULTS ###\n",
    "    ## Val\n",
    "    start_pred_val = time.time()\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    stop_pred_val = time.time()\n",
    "    pred_val_time = stop_pred_val - start_pred_val\n",
    "\n",
    "    accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "    precision_val = precision_score(y_val, y_pred_val)\n",
    "    recall_val = recall_score(y_val, y_pred_val)\n",
    "    f1_val = f1_score(y_val, y_pred_val)\n",
    "    auc_val = roc_auc_score(y_val,y_pred_val)\n",
    "    loss_val = log_loss(y_val,y_pred_val)\n",
    "    # Assume y_val and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_val, fp_val, fn_val, tp_val = confusion_matrix(y_val, y_pred_val).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_val = tp_val / (tp_val + fn_val) # Sensitivity\n",
    "    tnr_val = tn_val / (tn_val + fp_val) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_val = np.sqrt(tpr_val * tnr_val) \n",
    "    ## Test\n",
    "    start_pred_test = time.time()\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    stop_pred_test = time.time()\n",
    "    pred_test_time = stop_pred_test - start_pred_test\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    auc_test = roc_auc_score(y_test,y_pred_test)\n",
    "    loss_test = log_loss(y_test,y_pred_test)\n",
    "    # Assume y_test and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test, fp_test, fn_test, tp_test = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test = tp_test / (tp_test + fn_test) # Sensitivity\n",
    "    tnr_test = tn_test / (tn_test + fp_test) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test = np.sqrt(tpr_test * tnr_test)\n",
    "    \n",
    "    ## test imbalanced\n",
    "    start_pred_test_imbalanced = time.time()\n",
    "    y_pred_test_imbalanced = model.predict(X_test_imbalanced)\n",
    "    stop_pred_test_imbalanced = time.time()\n",
    "    pred_test_imbalanced_time = stop_pred_test_imbalanced - start_pred_test_imbalanced\n",
    "\n",
    "    accuracy_test_imbalanced = accuracy_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    precision_test_imbalanced = precision_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    recall_test_imbalanced = recall_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    f1_test_imbalanced = f1_score(y_test_imbalanced, y_pred_test_imbalanced)\n",
    "    auc_test_imbalanced = roc_auc_score(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    loss_test_imbalanced = log_loss(y_test_imbalanced,y_pred_test_imbalanced)\n",
    "    # Assume y_test_imbalanced and y_pred are the true and predicted labels for a binary classification problem\n",
    "    tn_test_imbalanced, fp_test_imbalanced, fn_test_imbalanced, tp_test_imbalanced = confusion_matrix(y_test_imbalanced, y_pred_test_imbalanced).ravel()\n",
    "    # Calculate TPR and TNR\n",
    "    tpr_test_imbalanced = tp_test_imbalanced / (tp_test_imbalanced + fn_test_imbalanced) # Sensitivity\n",
    "    tnr_test_imbalanced = tn_test_imbalanced / (tn_test_imbalanced + fp_test_imbalanced) # Specificity\n",
    "    # Calculate G-mean\n",
    "    gmean_test_imbalanced = np.sqrt(tpr_test_imbalanced * tnr_test_imbalanced) \n",
    "\n",
    "    print(confusion_matrix(y_test_imbalanced, y_pred_test_imbalanced))\n",
    "    val_results = [accuracy_val, precision_val, recall_val, f1_val, auc_val, loss_val, tnr_val]\n",
    "    test_results = [accuracy_test, precision_test, recall_test, f1_test, auc_test, loss_test, tnr_test]\n",
    "    test_imbalanced_results = [accuracy_test_imbalanced, precision_test_imbalanced, recall_test_imbalanced, f1_test_imbalanced, auc_test_imbalanced, loss_test_imbalanced, tnr_test_imbalanced]\n",
    "\n",
    "    time_results = [training_time, pred_val_time, pred_test_time, pred_test_imbalanced_time, sampling_time]\n",
    "    return val_results, test_results, test_imbalanced_results, time_results\n",
    "    # return accuracy, precision, recall, f1, auc, loss, tnr   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "kXQqS7aaQvg1"
   },
   "outputs": [],
   "source": [
    "def run_iterations(model, X, y, iterations=5):\n",
    "    results = []\n",
    "    random_state = [12,23,34,45,56]\n",
    "    for i in range(len(random_state)):\n",
    "        val_results, test_results, test_imbalanced_results, time_results = train_and_evaluate_model(model, X, y, random_state[i])\n",
    "        concatted_results = val_results + test_results + test_imbalanced_results + time_results\n",
    "    \n",
    "        results.append(concatted_results)\n",
    "\n",
    "    columns = ['Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1', 'Val AUC', 'Val Loss', 'Val Specificity',\n",
    "               'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1', 'Test AUC', 'Test Loss', 'Test Specificity',\n",
    "               'Test Imbalanced Accuracy', 'Test Imbalanced Precision', 'Test Imbalanced Recall', 'Test Imbalanced F1', 'Test Imbalanced AUC', 'Test Imbalanced Loss', 'Test Imbalanced Specificity',\n",
    "               'Training Time', 'Pred Val Time', 'Pred Test Time', 'Pred Test Imbalanced Time','Sampling_Time'\n",
    "               ]\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    print(df)\n",
    "    stats = df.describe().loc[['mean']]\n",
    "    # stats = df.describe()\n",
    "    print(stats)\n",
    "    return stats.to_csv(sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "4E5IscywJnxD"
   },
   "outputs": [],
   "source": [
    "# def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "#     recall = recall_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     auc = roc_auc_score(y_test,y_pred)\n",
    "#     loss = log_loss(y_test,y_pred)\n",
    "#     # Assume y_test and y_pred are the true and predicted labels for a binary classification problem\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#     # Calculate TPR and TNR\n",
    "#     tpr = tp / (tp + fn) # Sensitivity\n",
    "#     tnr = tn / (tn + fp) # Specificity\n",
    "#     # Calculate G-mean\n",
    "#     gmean = np.sqrt(tpr * tnr)\n",
    "#     return accuracy, precision, recall, f1, auc, loss, tnr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "ud_rXwDLLSzq"
   },
   "outputs": [],
   "source": [
    "# def run_iterations(model, X_train, y_train, X_test, y_test, iterations=5):\n",
    "#     results = []\n",
    "#     for i in range(iterations):\n",
    "#         accuracy, precision, recall, f1, auc, loss, tnr = train_and_evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "#         results.append([accuracy, precision, recall, f1, auc, loss, tnr])\n",
    "#     columns = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC', 'Loss', 'Specificity']\n",
    "#     df = pd.DataFrame(results, columns=columns)\n",
    "#     print(df)\n",
    "#     median = df.median()\n",
    "#     return median.to_csv(sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "zlsQKnxQIs3_"
   },
   "outputs": [],
   "source": [
    "def plot_auc(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    sns.set_style(\"darkgrid\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.lineplot(fpr, tpr, label='AUC = %0.2f' % roc_auc)\n",
    "    plt.title('ROC Curve')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "Lsu_EEI7klPU"
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(rfc, feature_names):\n",
    "    importances = rfc.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    names = [feature_names[i] for i in indices]\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.bar(range(len(feature_names)), importances[indices])\n",
    "    plt.xticks(range(len(feature_names)), names, rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "reLU6OXp_BqB"
   },
   "outputs": [],
   "source": [
    "# df_2_train = pd.concat([X_train, y_train], axis=1)\n",
    "# df_2_test = pd.concat([X_test, y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "6zlOBWie_BqC"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# # Save the DataFrame to a CSV file\n",
    "# df_2_test.to_csv('df_2_test.csv', index=False)\n",
    "\n",
    "# # Download the CSV file to your local machine\n",
    "# files.download('df_2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YZgEY9lPKzML",
    "outputId": "401bb74b-7eb9-4c7b-f68f-5275a1949ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71544 entries, 0 to 71543\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   account_id                                      71544 non-null  int64  \n",
      " 1   label                                           71544 non-null  int64  \n",
      " 2   order_count_with_promo_category_0               71544 non-null  float64\n",
      " 3   order_count_with_promo_category_1               71544 non-null  float64\n",
      " 4   order_count_with_promo_category_> 1             71544 non-null  float64\n",
      " 5   price_amount_category_0-280                     71544 non-null  float64\n",
      " 6   price_amount_category_281-870                   71544 non-null  float64\n",
      " 7   price_amount_category_871-2775                  71544 non-null  float64\n",
      " 8   price_amount_category_> 2775                    71544 non-null  float64\n",
      " 9   promo_amount_category_0-16                      71544 non-null  float64\n",
      " 10  promo_amount_category_16-81                     71544 non-null  float64\n",
      " 11  promo_amount_category_> 81                      71544 non-null  float64\n",
      " 12  category_f_order_count_with_promo_category_0    71544 non-null  float64\n",
      " 13  category_f_order_count_with_promo_category_1    71544 non-null  float64\n",
      " 14  category_f_order_count_with_promo_category_2    71544 non-null  float64\n",
      " 15  category_f_order_count_with_promo_category_> 2  71544 non-null  float64\n",
      " 16  category_f_promo_amount_category_0-16           71544 non-null  float64\n",
      " 17  category_f_promo_amount_category_17-70          71544 non-null  float64\n",
      " 18  category_f_promo_amount_category_> 70           71544 non-null  float64\n",
      "dtypes: float64(17), int64(2)\n",
      "memory usage: 10.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlI99wRS6O8x",
    "outputId": "c2cf7d3e-ba14-42b4-fa55-8987bd52c082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = df.isna().sum()\n",
    "selected_data = df.columns.isin(counts[(counts > 0 )].index)\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6rMLdhb6WnF",
    "outputId": "ea9307fb-9ec1-4004-b161-41269a19b300"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71544"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "rtujcoSWXI3l"
   },
   "outputs": [],
   "source": [
    "# X[X['day_to_first_transaction'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXpix0qfkdut"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3DOF7HI-4lC"
   },
   "source": [
    "## Base Model (Random Forest Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "r3s1YRlP-4lD",
    "outputId": "4962aea2-4e2f-47af-dc4d-0e311f8fbbaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[976 150]\n",
      " [ 84  41]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[978 148]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[998 128]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1010  116]\n",
      " [  62   63]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[989 137]\n",
      " [ 58  67]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.650679       0.771350    0.441640  0.561685  0.653559  12.590789   \n",
      "1      0.664269       0.767705    0.444992  0.563410  0.658633  12.100987   \n",
      "2      0.694644       0.818731    0.456998  0.586580  0.682906  11.006136   \n",
      "3      0.645883       0.779037    0.429688  0.553877  0.651014  12.763660   \n",
      "4      0.691447       0.825843    0.475728  0.603696  0.688891  11.121383   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.865478       0.674920        0.776163     0.447236  ...   \n",
      "1         0.872274       0.668530        0.798469     0.482280  ...   \n",
      "2         0.908815       0.678914        0.763636     0.485950  ...   \n",
      "3         0.872340       0.669329        0.789174     0.448947  ...   \n",
      "4         0.902054       0.682109        0.794521     0.473083  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.328            0.259494             0.597393   \n",
      "1                   0.456            0.345455             0.662281   \n",
      "2                   0.456            0.367742             0.671162   \n",
      "3                   0.504            0.414474             0.700490   \n",
      "4                   0.536            0.407295             0.707165   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0              6.741978                     0.866785       0.122929   \n",
      "1              6.223365                     0.868561       0.122502   \n",
      "2              5.647127                     0.886323       0.121900   \n",
      "3              5.128513                     0.896980       0.119948   \n",
      "4              5.618315                     0.878330       0.121751   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.010912        0.010557                   0.009870       0.006016  \n",
      "1       0.010830        0.010821                   0.010195       0.001825  \n",
      "2       0.010835        0.010822                   0.010190       0.001739  \n",
      "3       0.010897        0.010714                   0.010094       0.001613  \n",
      "4       0.010778        0.010597                   0.009930       0.001649  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall   Val F1   Val AUC   Val Loss  \\\n",
      "mean      0.669384       0.792533    0.449809  0.57385  0.667001  11.916591   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.884192        0.67476        0.784393     0.467499  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                   0.456            0.358892             0.667698   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean               5.87186                     0.879396       0.121806   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean        0.01085        0.010702                   0.010056       0.002568  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.6693844924060751\t0.7925331772689337\t0.4498092274734874\t0.5738495887395267\t0.6670007128282608\t11.916590760782459\t0.8841921981830344\t0.6747603833865814\t0.784392575841627\t0.4674993476695211\t0.585625348352974\t0.6714372402803294\t11.722824009623405\t0.8753751328911378\t0.8370903277378098\t0.29624065085427537\t0.45600000000000007\t0.3588917337723533\t0.6676980461811723\t5.8718597607530585\t0.8793960923623445\t0.12180600166320801\t0.010850334167480468\t0.01070232391357422\t0.010055780410766602\t0.0025683879852294923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Tv2V9sh7RA1"
   },
   "source": [
    "## Using Class Weight Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KEMdW6qk7SC6",
    "outputId": "9404e573-b674-480a-a1c1-2a8c3f1d9026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[976 150]\n",
      " [ 84  41]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[978 148]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[998 128]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1010  116]\n",
      " [  62   63]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[989 137]\n",
      " [ 58  67]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.650679       0.771350    0.441640  0.561685  0.653559  12.590789   \n",
      "1      0.664269       0.767705    0.444992  0.563410  0.658633  12.100987   \n",
      "2      0.694644       0.818731    0.456998  0.586580  0.682906  11.006136   \n",
      "3      0.645883       0.779037    0.429688  0.553877  0.651014  12.763660   \n",
      "4      0.691447       0.825843    0.475728  0.603696  0.688891  11.121383   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.865478       0.674920        0.776163     0.447236  ...   \n",
      "1         0.872274       0.668530        0.798469     0.482280  ...   \n",
      "2         0.908815       0.678115        0.763021     0.484298  ...   \n",
      "3         0.872340       0.669329        0.789174     0.448947  ...   \n",
      "4         0.902054       0.682109        0.794521     0.473083  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.328            0.259494             0.597393   \n",
      "1                   0.456            0.345455             0.662281   \n",
      "2                   0.456            0.367742             0.671162   \n",
      "3                   0.504            0.414474             0.700490   \n",
      "4                   0.536            0.407295             0.707165   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0              6.741978                     0.866785       0.122698   \n",
      "1              6.223365                     0.868561       0.127960   \n",
      "2              5.647127                     0.886323       0.127064   \n",
      "3              5.128513                     0.896980       0.131704   \n",
      "4              5.618315                     0.878330       0.122655   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.010686        0.010899                   0.010111       0.001641  \n",
      "1       0.011424        0.012022                   0.010542       0.001652  \n",
      "2       0.010702        0.010859                   0.010086       0.001717  \n",
      "3       0.012718        0.010562                   0.010037       0.001572  \n",
      "4       0.010926        0.010639                   0.009998       0.001628  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall   Val F1   Val AUC   Val Loss  \\\n",
      "mean      0.669384       0.792533    0.449809  0.57385  0.667001  11.916591   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.884192       0.674601        0.784269     0.467169  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                   0.456            0.358892             0.667698   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean               5.87186                     0.879396       0.126416   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean       0.011291        0.010996                   0.010155       0.001642  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.6693844924060751\t0.7925331772689337\t0.4498092274734874\t0.5738495887395267\t0.6670007128282608\t11.916590760782459\t0.8841921981830344\t0.6746006389776358\t0.784269469781021\t0.4671687691571244\t0.5853410084933055\t0.6712719510241311\t11.728581781730293\t0.8753751328911378\t0.8370903277378098\t0.29624065085427537\t0.45600000000000007\t0.3588917337723533\t0.6676980461811723\t5.8718597607530585\t0.8793960923623445\t0.12641630172729493\t0.011291122436523438\t0.010996198654174805\t0.010154962539672852\t0.0016420364379882812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCXK3bPlS6L4"
   },
   "source": [
    "## With hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gEC23mOL7b3N",
    "outputId": "69eafe54-f7df-44c4-f5a7-a96d24f82cd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[976 150]\n",
      " [ 84  41]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[978 148]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[998 128]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1010  116]\n",
      " [  63   62]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[989 137]\n",
      " [ 58  67]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.650679       0.771350    0.441640  0.561685  0.653559  12.590789   \n",
      "1      0.664269       0.767705    0.444992  0.563410  0.658633  12.100987   \n",
      "2      0.695444       0.819277    0.458685  0.588108  0.683750  10.977324   \n",
      "3      0.645084       0.778409    0.428125  0.552419  0.650233  12.792472   \n",
      "4      0.691447       0.825843    0.475728  0.603696  0.688891  11.121383   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.865478       0.674920        0.776163     0.447236  ...   \n",
      "1         0.872274       0.668530        0.798469     0.482280  ...   \n",
      "2         0.908815       0.678115        0.758974     0.489256  ...   \n",
      "3         0.872340       0.669329        0.789174     0.448947  ...   \n",
      "4         0.902054       0.682109        0.794521     0.473083  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.328            0.259494             0.597393   \n",
      "1                   0.456            0.345455             0.662281   \n",
      "2                   0.456            0.367742             0.671162   \n",
      "3                   0.496            0.409241             0.696490   \n",
      "4                   0.536            0.407295             0.707165   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0              6.741978                     0.866785       0.236105   \n",
      "1              6.223365                     0.868561       0.238052   \n",
      "2              5.647127                     0.886323       0.238058   \n",
      "3              5.157325                     0.896980       0.244245   \n",
      "4              5.618315                     0.878330       0.239286   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.020636        0.020194                   0.019089       0.001691  \n",
      "1       0.021016        0.020903                   0.019540       0.001756  \n",
      "2       0.020383        0.020785                   0.019441       0.001616  \n",
      "3       0.020708        0.020836                   0.020893       0.001668  \n",
      "4       0.020643        0.020418                   0.019228       0.001685  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "mean      0.669384       0.792517    0.449834  0.573864  0.667013  11.916591   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.884192       0.674601         0.78346     0.468161  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                  0.4544            0.357845             0.666898   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean              5.877622                     0.879396       0.239149   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean       0.020677        0.020627                   0.019638       0.001683  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.6693844924060752\t0.7925168281334506\t0.4498339956016492\t0.5738636360169013\t0.6670130968923418\t11.916590760782459\t0.8841921981830344\t0.6746006389776358\t0.783460174909226\t0.46816050469431447\t0.5858324444394671\t0.6713041402764974\t11.728581781730293\t0.8744477758586802\t0.8369304556354915\t0.295512510750076\t0.4544\t0.35784518174872987\t0.6668980461811722\t5.877622135395603\t0.8793960923623445\t0.23914918899536133\t0.02067723274230957\t0.020627260208129883\t0.01963815689086914\t0.001683187484741211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced', \n",
    "                            max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200)\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "id": "pboPJG6anvIY"
   },
   "outputs": [],
   "source": [
    "# # define the hyperparameter grid to search over\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# # n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# n_estimators = [50,100,200]\n",
    "# # Number of features to consider at every split\n",
    "# # max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [2,4,6,8,None]\n",
    "# # max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# # max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': n_estimators,\n",
    "#     # 'max_features': max_features,\n",
    "#     'max_depth': max_depth,\n",
    "#     'min_samples_split': min_samples_split,\n",
    "#     'min_samples_leaf': min_samples_leaf,\n",
    "#     'bootstrap': bootstrap\n",
    "# }\n",
    "\n",
    "# # create a random forest classifier object\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # create a grid search object\n",
    "# grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='f1', verbose=2)\n",
    "\n",
    "# # fit the grid search object to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # print the best hyperparameters and corresponding f1 score\n",
    "# print('Best hyperparameters:', grid_search.best_params_)\n",
    "# print('Best F1 score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "R2qrjWIpURxx"
   },
   "outputs": [],
   "source": [
    "# data_testing_01\n",
    "# Best hyperparameters: {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "\n",
    "\n",
    "# data_full_1\n",
    "# Best hyperparameters: {'bootstrap': False, 'max_depth': 6, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eDDRgTPamPN"
   },
   "source": [
    "## Hyperparameter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2zXjRJ9WUYYL",
    "outputId": "e5b20e90-b70c-4ddb-b345-96277798cd67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[976 150]\n",
      " [ 84  41]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[978 148]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[998 128]\n",
      " [ 68  57]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[1008  118]\n",
      " [  62   63]]\n",
      "Number of examples in the training set:  3753\n",
      "Number of examples in the validation set:  1251\n",
      "Number of examples in the test set:  1252\n",
      "Number of examples in the imbalanced test dataset (label 0): 1126\n",
      "Number of examples in the imbalanced test dataset (label 1): 125\n",
      "[[989 137]\n",
      " [ 58  67]]\n",
      "   Val Accuracy  Val Precision  Val Recall    Val F1   Val AUC   Val Loss  \\\n",
      "0      0.649880       0.769231    0.441640  0.561122  0.652749  12.619600   \n",
      "1      0.665068       0.768362    0.446634  0.564901  0.659454  12.072175   \n",
      "2      0.695444       0.819277    0.458685  0.588108  0.683750  10.977324   \n",
      "3      0.647482       0.778711    0.434375  0.557673  0.652539  12.706036   \n",
      "4      0.691447       0.824022    0.477346  0.604508  0.688910  11.121383   \n",
      "\n",
      "   Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "0         0.863857       0.674121        0.772334     0.448911  ...   \n",
      "1         0.872274       0.669329        0.798982     0.483821  ...   \n",
      "2         0.908815       0.676518        0.755102     0.489256  ...   \n",
      "3         0.870704       0.670128        0.788136     0.452188  ...   \n",
      "4         0.900474       0.682109        0.794521     0.473083  ...   \n",
      "\n",
      "   Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "0                   0.328            0.259494             0.597393   \n",
      "1                   0.456            0.345455             0.662281   \n",
      "2                   0.456            0.367742             0.671162   \n",
      "3                   0.504            0.411765             0.699602   \n",
      "4                   0.536            0.407295             0.707165   \n",
      "\n",
      "   Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "0              6.741978                     0.866785       0.109452   \n",
      "1              6.223365                     0.868561       0.111281   \n",
      "2              5.647127                     0.886323       0.108344   \n",
      "3              5.186137                     0.895204       0.109606   \n",
      "4              5.618315                     0.878330       0.107686   \n",
      "\n",
      "   Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "0       0.010568        0.010270                   0.009994       0.001726  \n",
      "1       0.010409        0.010309                   0.009833       0.001590  \n",
      "2       0.010245        0.010362                   0.009706       0.001676  \n",
      "3       0.010458        0.010262                   0.009837       0.001572  \n",
      "4       0.010366        0.010217                   0.009798       0.001625  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "      Val Accuracy  Val Precision  Val Recall    Val F1  Val AUC   Val Loss  \\\n",
      "mean      0.669864       0.791921    0.451736  0.575263  0.66748  11.899304   \n",
      "\n",
      "      Val Specificity  Test Accuracy  Test Precision  Test Recall  ...  \\\n",
      "mean         0.883225       0.674441        0.781815     0.469452  ...   \n",
      "\n",
      "      Test Imbalanced Recall  Test Imbalanced F1  Test Imbalanced AUC  \\\n",
      "mean                   0.456             0.35835              0.66752   \n",
      "\n",
      "      Test Imbalanced Loss  Test Imbalanced Specificity  Training Time  \\\n",
      "mean              5.883385                     0.879041       0.109274   \n",
      "\n",
      "      Pred Val Time  Pred Test Time  Pred Test Imbalanced Time  Sampling_Time  \n",
      "mean       0.010409        0.010284                   0.009834       0.001638  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "\tVal Accuracy\tVal Precision\tVal Recall\tVal F1\tVal AUC\tVal Loss\tVal Specificity\tTest Accuracy\tTest Precision\tTest Recall\tTest F1\tTest AUC\tTest Loss\tTest Specificity\tTest Imbalanced Accuracy\tTest Imbalanced Precision\tTest Imbalanced Recall\tTest Imbalanced F1\tTest Imbalanced AUC\tTest Imbalanced Loss\tTest Imbalanced Specificity\tTraining Time\tPred Val Time\tPred Test Time\tPred Test Imbalanced Time\tSampling_Time\n",
      "mean\t0.6698641087130296\t0.7919206581095921\t0.4517360274220775\t0.5752625836647296\t0.6674803942440516\t11.899303636854821\t0.8832247610660259\t0.67444089456869\t0.7818149328450328\t0.46945197769656505\t0.5863954845186841\t0.6711779339403924\t11.734339553837183\t0.8729038901842199\t0.8367705835331736\t0.29546284907026965\t0.45600000000000007\t0.35834993810671867\t0.6675204262877443\t5.883384510038147\t0.8790408525754885\t0.10927386283874511\t0.010409116744995117\t0.010284042358398438\t0.009833621978759765\t0.0016378402709960938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced', \n",
    "                            bootstrap = False, max_depth= 6, min_samples_leaf = 2, min_samples_split = 2, n_estimators = 100\n",
    "                              # bootstrap = False, max_depth= 10, min_samples_leaf = 4, min_samples_split = 2, n_estimators = 100\n",
    ")\n",
    "print(run_iterations(rf, X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
